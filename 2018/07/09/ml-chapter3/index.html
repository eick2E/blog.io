<!DOCTYPE html>
<html style="display: none;" lang="zh">
    <head>
    <meta charset="utf-8">
    <!--
        © Material Theme
        https://github.com/viosey/hexo-theme-material
        Version: 1.5.2 -->
    <script>
        window.materialVersion = "1.5.2"
        // Delete localstorage with these tags
        window.oldVersion = [
            'codestartv1',
            '1.3.4',
            '1.4.0',
            '1.4.0b1',
            '1.5.0'
        ]
    </script>

    <!-- dns prefetch -->
    <meta http-equiv="x-dns-prefetch-control" content="on">



    <link rel="dns-prefetch" href="https://busuanzi.ibruce.info"/>



        <link rel="dns-prefetch" href="https://cdn-city.livere.com"/>










    <!-- Meta & Info -->
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="renderer" content="webkit">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!-- Title -->
    
    <title>
        
            第三章 Training Model | 
        
        eickEe
    </title>

    <!-- Favicons -->
    <link rel="icon shortcut" type="image/ico" href="/img/titt.png">
    <link rel="icon" href="/img/titt.png">

    <meta name="format-detection" content="telephone=no"/>
    <meta name="description" itemprop="description" content="">
    <meta name="keywords" content=",Gradient Descent,模型训练,Logistic Regression,L1,L2">
    <meta name="theme-color" content="#0097A7">

    <!-- Disable Fucking Bloody Baidu Tranformation -->
    <meta http-equiv="Cache-Control" content="no-transform" />
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <!--[if lte IE 9]>
        <link rel="stylesheet" href="/css/ie-blocker.css">

        
            <script src="/js/ie-blocker.zhCN.js"></script>
        
    <![endif]-->

    <!-- Import lsloader -->
    <script>(function(){window.lsloader={jsRunSequence:[],jsnamemap:{},cssnamemap:{}};lsloader.removeLS=function(a){try{localStorage.removeItem(a)}catch(b){}};lsloader.setLS=function(a,c){try{localStorage.setItem(a,c)}catch(b){}};lsloader.getLS=function(a){var c="";try{c=localStorage.getItem(a)}catch(b){c=""}return c};versionString="/*"+(window.materialVersion||"unknownVersion")+"*/";lsloader.clean=function(){try{var b=[];for(var a=0;a<localStorage.length;a++){b.push(localStorage.key(a))}b.forEach(function(e){var f=lsloader.getLS(e);if(window.oldVersion){var d=window.oldVersion.reduce(function(g,h){return g||f.indexOf("/*"+h+"*/")!==-1},false);if(d){lsloader.removeLS(e)}}})}catch(c){}};lsloader.clean();lsloader.load=function(f,a,b,d){if(typeof b==="boolean"){d=b;b=undefined}d=d||false;b=b||function(){};var e;e=this.getLS(f);if(e&&e.indexOf(versionString)===-1){this.removeLS(f);this.requestResource(f,a,b,d);return}if(e){var c=e.split(versionString)[0];if(c!=a){console.log("reload:"+a);this.removeLS(f);this.requestResource(f,a,b,d);return}e=e.split(versionString)[1];if(d){this.jsRunSequence.push({name:f,code:e});this.runjs(a,f,e)}else{document.getElementById(f).appendChild(document.createTextNode(e));b()}}else{this.requestResource(f,a,b,d)}};lsloader.requestResource=function(b,e,a,c){var d=this;if(c){this.iojs(e,b,function(h,f,g){d.setLS(f,h+versionString+g);d.runjs(h,f,g)})}else{this.iocss(e,b,function(f){document.getElementById(b).appendChild(document.createTextNode(f));d.setLS(b,e+versionString+f)},a)}};lsloader.iojs=function(d,b,g){var a=this;a.jsRunSequence.push({name:b,code:""});try{var f=new XMLHttpRequest();f.open("get",d,true);f.onreadystatechange=function(){if(f.readyState==4){if((f.status>=200&&f.status<300)||f.status==304){if(f.response!=""){g(d,b,f.response);return}}a.jsfallback(d,b)}};f.send(null)}catch(c){a.jsfallback(d,b)}};lsloader.iocss=function(f,c,h,a){var b=this;try{var g=new XMLHttpRequest();g.open("get",f,true);g.onreadystatechange=function(){if(g.readyState==4){if((g.status>=200&&g.status<300)||g.status==304){if(g.response!=""){h(g.response);a();return}}b.cssfallback(f,c,a)}};g.send(null)}catch(d){b.cssfallback(f,c,a)}};lsloader.iofonts=function(f,c,h,a){var b=this;try{var g=new XMLHttpRequest();g.open("get",f,true);g.onreadystatechange=function(){if(g.readyState==4){if((g.status>=200&&g.status<300)||g.status==304){if(g.response!=""){h(g.response);a();return}}b.cssfallback(f,c,a)}};g.send(null)}catch(d){b.cssfallback(f,c,a)}};lsloader.runjs=function(f,c,e){if(!!c&&!!e){for(var b in this.jsRunSequence){if(this.jsRunSequence[b].name==c){this.jsRunSequence[b].code=e}}}if(!!this.jsRunSequence[0]&&!!this.jsRunSequence[0].code&&this.jsRunSequence[0].status!="failed"){var a=document.createElement("script");a.appendChild(document.createTextNode(this.jsRunSequence[0].code));a.type="text/javascript";document.getElementsByTagName("head")[0].appendChild(a);this.jsRunSequence.shift();if(this.jsRunSequence.length>0){this.runjs()}}else{if(!!this.jsRunSequence[0]&&this.jsRunSequence[0].status=="failed"){var d=this;var a=document.createElement("script");a.src=this.jsRunSequence[0].path;a.type="text/javascript";this.jsRunSequence[0].status="loading";a.onload=function(){d.jsRunSequence.shift();if(d.jsRunSequence.length>0){d.runjs()}};document.body.appendChild(a)}}};lsloader.tagLoad=function(b,a){this.jsRunSequence.push({name:a,code:"",path:b,status:"failed"});this.runjs()};lsloader.jsfallback=function(c,b){if(!!this.jsnamemap[b]){return}else{this.jsnamemap[b]=b}for(var a in this.jsRunSequence){if(this.jsRunSequence[a].name==b){this.jsRunSequence[a].code="";this.jsRunSequence[a].status="failed";this.jsRunSequence[a].path=c}}this.runjs()};lsloader.cssfallback=function(e,c,b){if(!!this.cssnamemap[c]){return}else{this.cssnamemap[c]=1}var d=document.createElement("link");d.type="text/css";d.href=e;d.rel="stylesheet";d.onload=d.onerror=b;var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(d,a)};lsloader.runInlineScript=function(c,b){var a=document.getElementById(b).innerText;this.jsRunSequence.push({name:c,code:a});this.runjs()}})();</script>

    <!-- Import queue -->
    <script>function Queue(){this.dataStore=[];this.offer=b;this.poll=d;this.execNext=a;this.debug=false;this.startDebug=c;function b(e){if(this.debug){console.log("Offered a Queued Function.")}if(typeof e==="function"){this.dataStore.push(e)}else{console.log("You must offer a function.")}}function d(){if(this.debug){console.log("Polled a Queued Function.")}return this.dataStore.shift()}function a(){var e=this.poll();if(e!==undefined){if(this.debug){console.log("Run a Queued Function.")}e()}}function c(){this.debug=true}}var queue=new Queue();</script>

    <!-- Import CSS -->
    
        <style id="material_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("material_css","/css/material.min.css?Z7a72R1E4SxzBKR/WGctOA==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
        <style id="style_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("style_css","/css/style.min.css?MKetZV3cUTfDxvMffaOezg==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>

        
            
                <style id="prettify_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("prettify_css","/css/prettify.min.css?zp8STOU9v89XWFEnN+6YmQ==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
                <style id="prettify_theme"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("prettify_theme","/css/prettify/github-v2.min.css?AfzKxt++K+/lhZBlSjnxwg==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
            
        

    

    

    <!-- Config CSS -->

<!-- Other Styles -->
<style>
  body, html {
    font-family: Roboto, "Helvetica Neue", Helvetica, "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "微软雅黑", Arial, sans-serif;
    overflow-x: hidden !important;
  }
  
  code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  a {
    color: #00838F;
  }

  .mdl-card__media,
  #search-label,
  #search-form-label:after,
  #scheme-Paradox .hot_tags-count,
  #scheme-Paradox .sidebar_archives-count,
  #scheme-Paradox .sidebar-colored .sidebar-header,
  #scheme-Paradox .sidebar-colored .sidebar-badge{
    background-color: #4586F3 !important;
  }

  /* Sidebar User Drop Down Menu Text Color */
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover,
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus {
    color: #4586F3 !important;
  }

  #post_entry-right-info,
  .sidebar-colored .sidebar-nav li:hover > a,
  .sidebar-colored .sidebar-nav li:hover > a i,
  .sidebar-colored .sidebar-nav li > a:hover,
  .sidebar-colored .sidebar-nav li > a:hover i,
  .sidebar-colored .sidebar-nav li > a:focus i,
  .sidebar-colored .sidebar-nav > .open > a,
  .sidebar-colored .sidebar-nav > .open > a:hover,
  .sidebar-colored .sidebar-nav > .open > a:focus,
  #ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a {
    color: #4586F3 !important;
  }

  .toTop {
    background: #757575 !important;
  }

  .material-layout .material-post>.material-nav,
  .material-layout .material-index>.material-nav,
  .material-nav a {
    color: #757575;
  }

  #scheme-Paradox .MD-burger-layer {
    background-color: #757575;
  }

  #scheme-Paradox #post-toc-trigger-btn {
    color: #757575;
  }

  .post-toc a:hover {
    color: #00838F;
    text-decoration: underline;
  }

</style>


<!-- Theme Background Related-->

    <style>
      body{
        background-color: #fff;
      }

      /* blog_info bottom background */
      #scheme-Paradox .material-layout .something-else .mdl-card__supporting-text{
        background-color: #fff;
      }
    </style>




<!-- Fade Effect -->

    <style>
      .fade {
        transition: all 800ms linear;
        -webkit-transform: translate3d(0,0,0);
        -moz-transform: translate3d(0,0,0);
        -ms-transform: translate3d(0,0,0);
        -o-transform: translate3d(0,0,0);
        transform: translate3d(0,0,0);
        opacity: 1;
      }

      .fade.out{
        opacity: 0;
      }
    </style>


<!-- Import Font -->
<!-- Import Roboto -->

    <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet">


<!-- Import Material Icons -->


    <style id="material_icons"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("material_icons","/css/material-icons.css?pqhB/Rd/ab0H2+kZp0RDmw==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>




    <!-- Import jQuery -->
    
        <script>lsloader.load("jq_js","/js/jquery.min.js?qcusAULNeBksqffqUM2+Ig==", true)</script>
    

    <!-- WebAPP Icons -->
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="application-name" content="eickEe">
    <meta name="msapplication-starturl" content="http://eickee.com/2018/07/09/ml-chapter3/">
    <meta name="msapplication-navbutton-color" content="#0097A7">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-title" content="eickEe">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon" href="/img/titt.png">

    <!-- Site Verification -->
    
    

    <!-- RSS -->
    

    <!-- The Open Graph protocol -->
    <meta property="og:url" content="http://eickee.com/2018/07/09/ml-chapter3/">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="第三章 Training Model | eickEe">
    <meta property="og:image" content="/img/titt.png">
    <meta property="og:description" content="">
    <meta property="og:article:tag" content="Gradient Descent"> <meta property="og:article:tag" content="模型训练"> <meta property="og:article:tag" content="Logistic Regression"> <meta property="og:article:tag" content="L1,L2"> 

    
        <meta property="article:published_time" content="Mon Jul 09 2018 15:54:50 GMT+0800">
        <meta property="article:modified_time" content="Mon Aug 27 2018 00:24:01 GMT+0800">
    

    <!-- The Twitter Card protocol -->
    <meta name="twitter:card" content="summary_large_image">

    <!-- Add canonical link for SEO -->
    
        <link rel="canonical" href="http://eickee.com/2018/07/09/ml-chapter3/index.html" />
    

    <!-- Structured-data for SEO -->
    
        


<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage": "http://eickee.com/2018/07/09/ml-chapter3/index.html",
    "headline": "第三章 Training Model",
    "datePublished": "Mon Jul 09 2018 15:54:50 GMT+0800",
    "dateModified": "Mon Aug 27 2018 00:24:01 GMT+0800",
    "author": {
        "@type": "Person",
        "name": "eickEe",
        "image": {
            "@type": "ImageObject",
            "url": "/img/selfie5.jpg"
        },
        "description": "F##$!%#%$^@ocus."
    },
    "publisher": {
        "@type": "Organization",
        "name": "eickEe",
        "logo": {
            "@type":"ImageObject",
            "url": "/img/titt.png"
        }
    },
    "keywords": ",Gradient Descent,模型训练,Logistic Regression,L1,L2",
    "description": "",
}
</script>


    

    <!-- Analytics -->
    
    
    

    <!-- Custom Head -->
    

</head>


    
        <body id="scheme-Paradox" class="lazy">
            <div class="material-layout  mdl-js-layout has-drawer is-upgraded">
                

                <!-- Main Container -->
                <main class="material-layout__content" id="main">

                    <!-- Top Anchor -->
                    <div id="top"></div>

                    
                        <!-- Hamburger Button -->
                        <button class="MD-burger-icon sidebar-toggle">
                            <span class="MD-burger-layer"></span>
                        </button>
                    

                    <!-- Post TOC -->

    
    <!-- Back Button -->
    <!--
    <div class="material-back" id="backhome-div" tabindex="0">
        <a class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"
           href="#" onclick="window.history.back();return false;"
           target="_self"
           role="button"
           data-upgraded=",MaterialButton,MaterialRipple">
            <i class="material-icons" role="presentation">arrow_back</i>
            <span class="mdl-button__ripple-container">
                <span class="mdl-ripple"></span>
            </span>
        </a>
    </div>
    -->


    <!-- Left aligned menu below button -->
    
    
    <button id="post-toc-trigger-btn"
        class="mdl-button mdl-js-button mdl-button--icon">
        <i class="material-icons">format_list_numbered</i>
    </button>

    <ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect" for="post-toc-trigger-btn" style="max-height:80vh; overflow-y:scroll;">
        <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#1-Closed-form"><span class="post-toc-number">1.</span> <span class="post-toc-text">1. Closed-form</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#1-1-Linear-regression"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">1.1 Linear regression</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-Gradient-Descent-in-Linear-Regression"><span class="post-toc-number">2.</span> <span class="post-toc-text">2. Gradient Descent in Linear Regression</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#2-1-Learning-Rate"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">2.1 Learning Rate</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#2-2-Batch-Gradient-Descent"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">2.2 Batch Gradient Descent</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#2-3-Stochastic-Gradient-Descent"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">2.3 Stochastic Gradient Descent</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#2-4-Mini-batch-Gradient-Descent"><span class="post-toc-number">2.4.</span> <span class="post-toc-text">2.4 Mini-batch Gradient Descent</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#3-GD-in-Logistic-Regression"><span class="post-toc-number">3.</span> <span class="post-toc-text">3. GD in Logistic Regression</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#3-1-Learning-curve"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">3.1 Learning curve</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#3-2-Regularized-Linear-Models"><span class="post-toc-number">3.2.</span> <span class="post-toc-text">3.2 Regularized Linear Models</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#3-3-Logistic-Regression"><span class="post-toc-number">3.3.</span> <span class="post-toc-text">3.3 Logistic Regression</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#3-4-Softmax-Regression"><span class="post-toc-number">3.4.</span> <span class="post-toc-text">3.4 Softmax Regression</span></a></li></ol></li></ol>
    </ul>
    




<!-- Layouts -->

    <!-- Post Module -->
    <div class="material-post_container">

        <div class="material-post mdl-grid">
            <div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col">

                <!-- Post Header(Thumbnail & Title) -->
                
    <!-- Paradox Post Header -->
    
        <!-- Custom Thumbnail -->
        <div class="post_thumbnail-custom mdl-card__media mdl-color-text--grey-50" style="background-image:url(/img/chapter3/post3.png)">
    
            <p class="article-headline-p">
                第三章 Training Model
            </p>
        </div>





                
                    <!-- Paradox Post Info -->
                    <div class="mdl-color-text--grey-700 mdl-card__supporting-text meta">

    <!-- Author Avatar -->
    <div id="author-avatar">
        <img src="/img/selfie5.jpg" width="44px" height="44px" alt="Author Avatar"/>
    </div>
    <!-- Author Name & Date -->
    <div>
        <strong>eickEe</strong>
        <span>7月 09, 2018</span>
    </div>

    <div class="section-spacer"></div>

    <!-- Favorite -->
    <!--
        <button id="article-functions-like-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon btn-like">
            <i class="material-icons" role="presentation">favorite</i>
            <span class="visuallyhidden">favorites</span>
        </button>
    -->

    <!-- Qrcode -->
    

    <!-- Tags (bookmark) -->
    
    <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
        <i class="material-icons" role="presentation">bookmark</i>
        <span class="visuallyhidden">bookmark</span>
    </button>
    <ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button">
        <li class="mdl-menu__item">
        <a class="post_tag-link" href="/tags/Gradient-Descent/">Gradient Descent</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/L1-L2/">L1,L2</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/Logistic-Regression/">Logistic Regression</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/模型训练/">模型训练</a>
    </ul>
    

    <!-- Share -->
    
        <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
    <i class="material-icons" role="presentation">share</i>
    <span class="visuallyhidden">share</span>
</button>
<ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button">
    

    
        
            <!-- Busuanzi Views -->
            <a class="post_share-link" href="#">
                <li class="mdl-menu__item">
                    <span id="busuanzi_container_page_pv">
                        <span id="busuanzi_value_page_pv"></span>&nbsp;浏览量
                    </span>
                </li>
            </a>
        
    

    <!-- Share Weibo -->
    
        <a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=第三章 Training Model&url=http://eickee.com/2018/07/09/ml-chapter3/index.html&pic=http://eickee.com/img/titt.png&searchPic=false&style=simple" target="_blank">
            <li class="mdl-menu__item">
                分享到微博
            </li>
        </a>
    

    <!-- Share Twitter -->
    
        <a class="post_share-link" href="https://twitter.com/intent/tweet?text=第三章 Training Model&url=http://eickee.com/2018/07/09/ml-chapter3/index.html&via=eickEe" target="_blank">
            <li class="mdl-menu__item">
                分享到 Twitter
            </li>
        </a>
    

    <!-- Share Facebook -->
    
        <a class="post_share-link" href="https://www.facebook.com/sharer/sharer.php?u=http://eickee.com/2018/07/09/ml-chapter3/index.html" target="_blank">
            <li class="mdl-menu__item">
                分享到 Facebook
            </li>
        </a>
    

    <!-- Share Google+ -->
    
        <a class="post_share-link" href="https://plus.google.com/share?url=http://eickee.com/2018/07/09/ml-chapter3/index.html" target="_blank">
            <li class="mdl-menu__item">
                分享到 Google+
            </li>
        </a>
    

    <!-- Share LinkedIn -->
    

    <!-- Share QQ -->
    

    <!-- Share Telegram -->
    
</ul>

    
</div>

                

                <!-- Post Content -->
                <div id="post-content" class="mdl-color-text--grey-700 mdl-card__supporting-text fade out">
    
        <p>上一章中总结了一个完整的从数据下载到预处理到最后模型评价的过程，其中模型的训练部分事实上只有一行，fit()。用着当然是方便，不过这后面的训练方式确是多种多样又蕴含“人生哲理”的，在这章总结了两种（事实上主要是后一种）主要的模型训练的方法，后一种gradient descent也是最近大热的deep learning的训练参数的基础。</p>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>


<p>There are two approaches for training parameters: <strong>Closed-form</strong>, <strong>Gradient descent</strong>.</p>
<h2 id="1-Closed-form"><a href="#1-Closed-form" class="headerlink" title="1. Closed-form"></a>1. Closed-form</h2><p>Using a direct “closed-form” equation (math equation) that directly computes the model parameters that best fit the model to the training set.</p>
<h3 id="1-1-Linear-regression"><a href="#1-1-Linear-regression" class="headerlink" title="1.1 Linear regression"></a>1.1 Linear regression</h3><ul>
<li><strong>Cost function</strong>:<br>$$loss=||X\beta-y||^2$$</li>
<li><strong>Minimize the cost function</strong>:<br>$$\hat{\beta}=argmin_\beta||X\beta-y||^2$$</li>
<li><strong>Closed form equation</strong>:<br>$$\hat{\beta}=(X^TX)^{-1}X^Ty$$</li>
</ul>
<p>– 第一种方法就是Closed-form，用数学的公式直接计算（这里是一个最小二乘法的例子），好处显而易见，一步到位，直接得到理想参数。缺点嘛，自然也是明显的，一方面，要找到合适的closed form solution是极其困难的，模型也是多种多样。其次，即使是Linear regression的closed form solution，在面对高维度的特征量时，训练速度也会大幅度下降。<br>这时候，就需要另一个思路的解决方法了，也就是另一位带头带哥来了—“GD”。当然，这里不是在说G-dragon，而是Gradient Descent，梯度下降。</p>
<h2 id="2-Gradient-Descent-in-Linear-Regression"><a href="#2-Gradient-Descent-in-Linear-Regression" class="headerlink" title="2. Gradient Descent in Linear Regression"></a>2. Gradient Descent in Linear Regression</h2><p>Gradient Descent is a very generic optimization algorithm capable of finding  optimal solution to a wide range of problems. The general idea of Gradient Descent is to tweak parameters iteratively in order to minimize a cost function.</p>
<p>进入正题前，先唠叨几句：</p>
<ul>
<li>我个人的理解一些梯度下降法（准确的是在说 Gradient-based 不只是GD）的重要性：<ul>
<li>直接的一点就是，解决了模型最优化（训练）的问题，且具有模型普适性（只要其cost function得当）；</li>
<li>解决了内存不足的问题，可分batch训练；</li>
<li>带来了online learning的可行性（原因同2）；</li>
</ul>
</li>
<li>这章主要是针对Linear 和Logistic Regression来讲述GD的，其他模型的思路大体相同；</li>
<li>基于gradient的方法不止GD一种，也包括高斯牛顿法等，这章就不整理了哈；</li>
<li>这章将整理几种基础GD的方式，后面针对于Nerual Network的GD的优化（如Adam等）会整理在后面的Deep learning篇里；</li>
<li>这里同样分享一个大牛的Post，也是专门讲解Gradient Descent的：<a href="http://ruder.io/optimizing-gradient-descent/index.html" target="_blank" rel="noopener">http://ruder.io/optimizing-gradient-descent/index.html</a></li>
</ul>
<p>简单的说梯度下降，</p>
<ul>
<li>如同之前的最小二乘法，运用上一章提到的如MSE等方式建立一个Cost Function，这个Function的值越小，证明模型越理想。GD的目的就是一步一步去调整各个参数的值，慢慢寻找到使得function最小的参数们的值。</li>
<li>举个例子，假设Cost function的形状是一座山，这个寻找的过程，有点像从这个山上的一个位置下山（假设参数量是2维的），起始点（参数的初始化决定）开始要找下山的方向，这里的方向也就是负梯度（负导数）的方向，走一段（沿这个方向走的距离又由learning rate决定），然后掏出地图（再次求导）看看下山的方向，重复，直到走到山底。当然这个比较理想化，也可能是一个山腰，但由于我们不敢迈大步子，所以找不到更低的路。（存在Local minimum）</li>
</ul>
<p>接下来，详细整理下这个下山的各个环节。</p>
<h3 id="2-1-Learning-Rate"><a href="#2-1-Learning-Rate" class="headerlink" title="2.1 Learning Rate"></a>2.1 Learning Rate</h3><ul>
<li>Decide the <strong>size of steps</strong>:<div align="center"><br><img src="/img/chapter3/2.1.1.png" width="350" hegiht="200" align="center"><br></div></li>
<li><strong>Not all</strong> the cost function look like nice regular bowls. There may be holes, ridges plateaus, etc.<br><div align="center"><br><img src="/img/chapter3/2.1.2.png" width="350" hegiht="200" align="center"><br></div><br>这里就是刚刚提到的步子迈太大或太小以及存在半山腰所带来的问题                </li>
<li>Shape of cost function could be an elongated bowl if the features have very <em>different scales</em>:<br><div align="center"><br><img src="/img/chapter3/2.1.3.png" width="400" hegiht="200" align="center"><br></div><br><em>Using Gradient Descent, you should ensure that all features have a <strong>similar scale</strong> by StandardScaler class.</em><br>这里解释了需要做scaling原因，梯度下降都会沿着这一区域下降最快的方向，所以如果出现图1中的情况，显然，每个局部的最佳不代表整体的最佳方向，所以要做scaling。</li>
</ul>
<h3 id="2-2-Batch-Gradient-Descent"><a href="#2-2-Batch-Gradient-Descent" class="headerlink" title="2.2 Batch Gradient Descent"></a>2.2 Batch Gradient Descent</h3><ol>
<li><strong>Partial derivative of cost function</strong>:<ul>
<li>Cost Function(MSE)</li>
<li>Partial derivative of MSE at feature j:<br>$$\frac{\partial MSE(\theta)}{\partial \theta_j}=\frac{2}{m}\sum_{i=1}^m (\theta^T\cdot x^{(i)}-y^{(i)})x^{(i)}_j$$</li>
</ul>
</li>
<li><strong>Gradient Vector</strong>:<br>$$\nabla_\theta MSE(\theta)=\left(<br>\begin{matrix}<br>\frac{\partial}{\partial_0}MSE(\theta) \newline<br>\frac{\partial}{\partial_1}MSE(\theta) \newline<br>… \newline<br>\frac{\partial}{\partial_n}MSE(\theta) \newline<br>\end{matrix}\right)=\frac{2}{m}X^T\cdot(X\cdot\theta -y)$$<br> <em>It uses the  whole batch of training data at every step.</em></li>
<li><strong>Gradient Descent Step</strong>:<br>$$\theta^{(next step)} = \theta-\eta\nabla_\theta MSE(\theta)$$<br><em>- Use grid search to find good learning rate;</em><br><em>- Interrupt the algorithm when the gradient vector becomes tiny.</em></li>
</ol>
<pre><code class="py">import numpy as np
n_epoch = 50 #迭代次数，一个epoch是走完一整个数据集
eta = 0.1    #learning rate
m = 100      #数据总数
def batch_gradient_descent(n_epoch, X, y, m):
    theta = np.random.randn(2,1)                               #初始化参数
    for epoch in range(n_epcoh):
        gradients = 2/m * X.T.dot(X.dot(theta)-y)            #计算整个batch的导数
        theta = theta - eta * gradients                     #梯度下降
    return theta
</code></pre>
<p>这里简单的实现了一下Batch Gradient Descent，首先用MSE建立cost function，第一步的负偏导数也就是找各个参数的下降方向（这里因为是Batch的方法，所以计算参考了每个数据（m），然后做了一个平均），平均后也就得到后一步的Gradient Vector，乘上eta（learning rate），让参数们加上这个变化量就行了（是不是简单明了（滑稽脸））。<br>然而，一个问题出现了，每次算方向，岂不是都要一口气把整个batch送进去算（所以数据）？对的，所以时间和内存代价就来了。然后就出现了接下来这种stochastic的方法。</p>
<h3 id="2-3-Stochastic-Gradient-Descent"><a href="#2-3-Stochastic-Gradient-Descent" class="headerlink" title="2.3 Stochastic Gradient Descent"></a>2.3 Stochastic Gradient Descent</h3><p>SGD just picks a random instance in the training set at every step and computes the gradients based only on that single instance.</p>
<div align="center"><br><img src="/img/chapter3/2.3.png" width="400" hegiht="200" align="center"><br></div>

<ul>
<li>It decreases only on average and ends up very close to the minimum;</li>
<li>The final parameter values are good, but not optimal;</li>
<li>It can help algorithm jump out of local minima;</li>
<li>The steps start out large, then get smaller and smaller( simulated annealing).</li>
</ul>
<pre><code class="py">n_epoch = 50
t0,t1=5,50

#这里稍微不同，由于随机的特点，做了一个简单learning rate的规划（越来越小）。
def learning_schedule(t):
    return t0/(t+t1)

def stochastic_gradient_descent(n_epoch, X, y, m):
    theta = np.random.randn(2,1)
    for epoch in range(n_epcoh):
        for i in range(m):
            random_index = np.random.randint(m)            #随机选一个而不是全部
            xi = X[random_index:random_index+1]
            yi = y[random_index:random_index+1]        
            gradients= 2*xi.T.dot(xi.dot(theta)-yi)
            eta = learning_schedule(epoch * m + i)        #运用刚刚的learning规划
            theta = theta - eta*gradients
    return theta
</code></pre>
<p>这里也简单的实现了这种方法，唯一的不同也就是把这个batch换成每次随机选一个。优缺点如上 ^ 。</p>
<h3 id="2-4-Mini-batch-Gradient-Descent"><a href="#2-4-Mini-batch-Gradient-Descent" class="headerlink" title="2.4 Mini-batch Gradient Descent"></a>2.4 Mini-batch Gradient Descent</h3><p>Mini-batch GD computes the gradients on small random sets of instances called mini-batches.</p>
<div align="center"><br><img src="/img/chapter3/2.4.png" width="400" hegiht="200" align="center"><br></div>

<ul>
<li>Get a performance boost from hardware optimization of matrix operations. Especially in GPUs;</li>
<li>Less erratic(不稳定)  than Stochastic GD<br>其实这种方法也就是综合一下前两种，既不全都也不单个，用一小块。其实，在machine learning的算法中，这种例子很多，比如还有后面的Elastic Net正则化的方法，比如在“未来”章节中的Adam最优化，毕竟站在巨人的肩膀上才是捷径嘛～</li>
</ul>
<h2 id="3-GD-in-Logistic-Regression"><a href="#3-GD-in-Logistic-Regression" class="headerlink" title="3. GD in Logistic Regression"></a>3. GD in Logistic Regression</h2><p>讲Logistic之前，先说两个GD中的两个技巧。</p>
<h3 id="3-1-Learning-curve"><a href="#3-1-Learning-curve" class="headerlink" title="3.1 Learning curve"></a>3.1 Learning curve</h3><p>These are plots of the model’s performance on the training set and the validation set as a function of the training set size(or iteration):</p>
<div align="center"><br><img src="/img/chapter3/3.1.png" width="400" hegiht="200" align="center"><br></div>

<ul>
<li>The learning curves are typical of an underfitting model. Both curves have reached a plateau, close and fairly high;</li>
<li>The gap between the curves is the hall-mark of an overfitting model.<br>Leraning curve的好处就在于既可以看到是否overfitting（两个线间的距离）又可以看到是否underfitting（两者在测试中的表现）</li>
</ul>
<h3 id="3-2-Regularized-Linear-Models"><a href="#3-2-Regularized-Linear-Models" class="headerlink" title="3.2 Regularized Linear Models"></a>3.2 Regularized Linear Models</h3><p>正则化（regularization）的思想简单的讲就是，在cost function中加入一个正则项来做penalty，防止其对训练数据集调整过度，导致的overfitting的问题。这里介绍了3种基本的正则项。<br>3 ways to constrain weights of model: <strong>Ridge Regression</strong>, <strong>Lasso Regression</strong>,<strong>Elastic Net</strong>.</p>
<ul>
<li><p><strong>Ridge Regression</strong>(Tikhonov regularization, L2)<br>A regression term l2 is added to the cost function:<br>$$J(\theta)=MSE(\theta)+\alpha\frac{1}{2}\sum_{i=1}^n{\theta_i^2}$$<br><em>It’s important to scale the data;</em></p>
</li>
<li><p><strong>Lasso Regression</strong>(L1)<br>  A regression term l1 is added to the cost function:<br>$$J(\theta)=MSE(\theta)+\alpha\sum_{i=1}^n{|\theta_i|}$$    </p>
<ul>
<li>An important characteristic of Lasso Regression is that it tends to completely eliminate the weights of the weights of the least important features;</li>
<li>Lasso Regression automatically performs feature selection and outputs a sparse model;</li>
<li>Lasso Regression is not differentiable at 0, so use a subgradient vector g when any weights=0.<br>$$g(\theta,J)=\nabla_\theta MSE(\theta)+\alpha\left(<br>\begin{matrix}<br>sign(\theta_1) \newline<br>sign(\theta_2) \newline<br>… \newline<br>sign(\theta_n) \newline<br>\end{matrix}<br>\right) \text{where} \ sign(\theta_i)=<br>\begin{cases}<br>-1, &amp; \text{if $ \ \theta_i&lt;0$} \newline<br>0, &amp; \text{if $ \ \theta_i=0$} \newline<br>+1, &amp; \text{if $ \ \theta_i&gt;0$} \newline<br>\end{cases}<br>$$</li>
<li><strong>Comparison</strong> of Ridge and Lasso:<br><div align="center"><br><img src="/img/chapter3/3.2.1.png" width="400" hegiht="200" align="center"><br></div>        <ul>
<li>L1 tends to screen the features(also against the overfitting), and L2 tends to avoid the overfitting.</li>
<li>书中对这张图的说明并不是很充分，这里给出我的几个对于L1和L2的见解：<ul>
<li>比较权威的解释为何对比l2，l1会更倾向优先筛选特征，形成一个稀疏矩阵。可以参考<a href="https://blog.csdn.net/qq_34531825/article/details/52689654" target="_blank" rel="noopener">https://blog.csdn.net/qq_34531825/article/details/52689654</a> 这篇文章，主要的思想就是在几何图形上找出正则项和原Cost Function的交点，由于l1的几何图形为菱形的特点，交点大部分坐落在坐标轴上。原文考虑的很周全，详情参考原文，<div align="center"><br><img src="/img/chapter3/3.2.3.png" width="400" hegiht="200" align="center"><br><br><br></div>    </li>
<li>其实吧，我也有一种自己的想法（仅个人意见），只看正则项的图形的话：左上的l1对比左下的l2优先接近某一坐标轴，也就是间接优先使得一项参数归0，这也就是为什么有了“筛选”这一功能。这一点可以通过两个正则项的形状来解释，l1由于绝对值的计算，图像倾向于一个菱形，而l2则是椭圆，从最优下降方向来讲，自然是l1沿着棱形边的垂直角度，所以大部分的可能会优先去接近于某个坐标轴，而相比棱形的椭圆则是可能会接近但不会交于某个坐标轴。</li>
<li>所以从上面的角度也可以讲，l1一般的情况下，下降速度要快于l2。</li>
<li>当然，这样一说岂不是l1美滋滋，l2滚出克了嘛？回答当然是no了。l2的好处是很多的。其一，最明显的就是，l2每个地方都可导，实现比较方便。再者，l2可以很好处理condition number不好导致的求逆矩阵困难的问题，这个在此不做扩展了，详情可以看一下<a href="http://pengshuang.space/2017/03/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84L1-%E5%92%8C-L2/" target="_blank" rel="noopener">http://pengshuang.space/2017/03/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84L1-%E5%92%8C-L2/</a></li>
<li>总结呢，一句话好了，l1倾向于平滑参数，l2倾向于筛选。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Elastic Net</strong><br>  This is middle ground between Ridge Regression and Lasso Regression. The regularization term is a simple mix of both L1 and L2.<br>  $$J(\theta)=MSE(\theta)+r\alpha\sum_{i=1}^m|\theta_i|+\frac{1-r}{2}\alpha\sum_{i=1}^m\theta_i^2$$<br>  如上面讲的，综合一哈就完事了～                </p>
</li>
<li><strong>Early Stopping</strong><br>This is method which try to stop training as soon as the validation error reaches a minimum.<br><div align="center"><br><img src="/img/chapter3/3.2.2.png" width="400" hegiht="200" align="center"><br></div><br>这个方式是非常直接的减少overfitting问题的方法，实现简单，效果拔群。好了，接下来进入正题吧。</li>
</ul>
<h3 id="3-3-Logistic-Regression"><a href="#3-3-Logistic-Regression" class="headerlink" title="3.3 Logistic Regression"></a>3.3 Logistic Regression</h3><p>Logistic Regression is commonly used to estimate the probability that an instance belongs to a particular class.<br>加一点自己的理解：</p>
<ul>
<li>Logistic R和Linear R都是一种Generalized linear model，只不过Logistc Regression（这里简称LR）是吧Linear R的结果输入进一个预测函数（sigmoid）。其一，Sigmoid函数引入了非线性因素。其二，sigmoid函数讲结果输出在（0，1）。这样可以轻松处理（0 or 1）的二分类问题。（这里的0～1不是概率，而是一种可能性）</li>
<li><p>插个题外话，其实get到了LR，也就get到了Nerual Network中的neruon的概念，LR就可以当作一个neruon来看待，只不过这里用的是sigmoid作为activive function。</p>
</li>
<li><p><strong>Estimating Probabilities</strong>:</p>
<ul>
<li>Logistic Regression also computes a weighted sum of the input features( with a bias term), and outputs the logistic of this result:<br>$$\hat{p}=h_\theta(x)=\sigma(\theta^T\cdot x)$$</li>
<li>Logistic function ( sigmoid function):<br>$$\sigma(t)=\frac{1}{1+e^{-t}}$$<div align="center"><br><img src="/img/chapter3/3.3.png" width="400" hegiht="200" align="center"><br></div>
</li>
</ul>
</li>
<li><p><strong>Training and Cost Function</strong></p>
<ul>
<li>在上一小节，我们对Linear R用MSE来作为cost function，然而这招对于LR不太成，我们看一下，假设我们继续MSE的话，LR的cost fucntion就会变成这个样子（copy个图，有空自己重新补个）：<br><div align="center"><br><img src="https://camo.githubusercontent.com/bde8204ff85b0b35fe8992d385e171af3e4ee30a/687474703a2f2f35326f70656e636f757273652e636f6d2f3f71613d626c6f622671615f626c6f6269643d363037343335323935303439373831373235" width="300" hegiht="200" align="center"><br><br><br></div><br>显然，存在了local minimum，因此，单纯的用MSE在LR这是行不通的，所以就有下面的Cost function</li>
<li><p>Cost function of a single training instance:<br>$$c(\theta)=<br>\begin{cases}<br>-\log(\hat{p}), &amp; \text{if y=1} \newline<br>-\log(1-\hat{p}), &amp; \text{if y=0} \newline<br>\end{cases}$$</p>
</li>
<li><p>Logistic Regression cost function:<br>$$J(\theta)=-\frac{1}{m}\sum_{i=1}^m[y^{(i)}\log(\hat{p}^{(i)})+(1-y^{(i)})\log(1-\hat{p}^{(i)})]$$</p>
</li>
<li>Partial derivatives:<br>$$\frac{\partial}{\partial\theta_j}J(\theta)=-\frac{1}{m}\sum_{i=1}^m(\sigma(\theta^T\cdot x^{(i)})-y^{(i)})x_j^{(i)}$$</li>
<li>公式简洁明了，书中没有具体解释这，这里有多种解释的方式，我尽力总结，水平有限，欢迎指正。<ul>
<li>第一种简单明了的方式，可以直接公式字面意义上理解，取对数是为了方便后面偏导数，单调性并没有改变，结果越接近样本本身的label的话，cost function值越小。当然，这不严谨（岂止不严谨ㅋㅋㅋㅋㅋㅋ），所以严谨的来了，最大似然估计。</li>
<li>实时上，linear R也可以通过最大似然来推出cost function，这里就不做整理了，推荐个详细的post：<a href="http://www.hanlongfei.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/08/05/mle/" target="_blank" rel="noopener">http://www.hanlongfei.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/08/05/mle/</a> 。ok，回到LR，简单的来推一下，把LR想成一个二项分布（LR模型就建立在“样本分类标签满足二项分布”的假设上），那么：<br>$$P(\hat{y}^{(i)}=1|x^{(i)};\theta) = h_{\theta}(x^{(i)})$$<br>$$P(\hat{y}^{(i)}=0|x^{(i)};\theta) = 1-h_{\theta}(x^{(i)})$$<br>求得的似然函数则为：<br>$$L=\prod_{i=1}^mP(\hat{y}^{(i)}=1|x^{(i)})^{\hat{y}(i)}\cdot P(\hat{y}^{(i)}=0|x^{(i)})^{(1-\hat{y}(i))}$$<br>这里的h（x）就是LR的预测函数，然后取个对数，单调性不变：<br>$$L=\sum_{i=1}^m[\hat{y}^{(i)}\log(h_{\theta}(x^{(i)}))+(1-\hat{y}^{(i)})\log(1-h_{\theta}(x^{(i)}))]$$<br>厉害了，是不是已经很像了？求最大似然，也就是求取-L的最小值，在平均一下：<br>$$J(\theta)=-\frac{1}{m}\sum_{i=1}^m[\hat{y}^{(i)}\log(h_{\theta}(x^{(i)}))+(1-\hat{y}^{(i)})\log(1-h_{\theta}(x^{(i)}))]$$<br>成了，cost function搞定，至于偏导后那么简洁几乎和Linear R一样的梯度参数，其实就是带入求导，我之前在纸上尝试过，就是过程比较繁琐，不算上矩阵求偏导，基本就是高中导数题，这里就不做整理了。</li>
<li>当然，也可以像后面的softmax一样，用交叉熵（cross entropy）的思想来解释，这里就需要信息熵、信息量等概念，一会具体解释。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="3-4-Softmax-Regression"><a href="#3-4-Softmax-Regression" class="headerlink" title="3.4 Softmax Regression"></a>3.4 Softmax Regression</h3><p>Logistic Regression model can be generalized to support multiple classes directly which is called Softmax Regression or Multinomial Logistic Regression.<br>直白的理解就是扩展了LR，不止可以分类两种。正因如此，Softmax的损失函数依然可以通过上面的方法理解和推倒。</p>
<ul>
<li><strong>Compute Softmax score for class k</strong>:<br>$$s_k(x)=\theta_k^T\cdot x$$</li>
<li><strong>Softmax function</strong>:<br>$$\hat{p}_k=\sigma(s(x))_k=\frac{e^{s_k(x)}}{\sum_{j=1}^ke^{s_j(x)}}$$</li>
<li><strong>Classifier prediction</strong>:<br>$$\hat{y}=argmax_k\sigma(s(x))_k=argmax_k s_k(x)=argmax_k(\theta_k^T\cdot x)$$<br><em>Softmax Regression predicts only one class at a time( can not recognize multiple people in one picture).</em></li>
<li><strong>Cross entropy cost function</strong>:<br>$$J(\Theta)=-\frac{1}{m}\sum_{i=1}^m\sum_{k=1}^K y_k^{(i)}\log(\hat{p}_k^{(i)})$$<br>这里插一句，在LR中，我们最后提到了可以用交叉熵来解释损失函数，这点在Softmax中更加明显。简单的讲就是运用真实分布来衡量预测结果，内容比较多，找个时间在写篇小的总结。</li>
<li><strong>Cross entropy gradient vector for class k</strong>:<br>$$\nabla_{\theta_k}J(\Theta)=\frac{1}{m}\sum_{i=1}^m(\hat{p}_k^{(i)}-y_k^{(i)})x^{(i)}$$</li>
</ul>
<p>好了，终于。这章的内容真是，越写越多，能扩展的东西也很多很多，有机会就小补一下。<br>下一章有点纠结是继续Machine learning基础的model还是直接复习Deep Learning了，反正都是坑555</p>

        
    

    
</div>


                

                <!-- Post Comments -->
                
                    
    <!-- 使用 来必力 -->
<div id="livere-comment">
    <div id="lv-container" data-id="city" data-uid="MTAyMC8zNzEyMi8xMzY1OA==">
	<script type="text/ls-javascript" id="livere-comment-js">
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];
       if (typeof LivereTower === 'function') { return; }
       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;
       e.parentNode.insertBefore(j, e);
   })(document, 'script');
	</script>
</div>
</div>
<style>
    #livere-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>

                
            </div>

            <!-- Post Prev & Next Nav -->
            <nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col">
    <!-- Prev Nav -->
    
        <a href="/2018/07/26/dl-chapter1/" id="post_nav-newer" class="prev-content">
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_back</i>
            </button>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            新篇
        </a>
    

    <!-- Section Spacer -->
    <div class="section-spacer"></div>

    <!-- Next Nav -->
    
        <a href="/2018/06/22/ml-chapter2/" id="post_nav-older" class="next-content">
            旧篇
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_forward</i>
            </button>
        </a>
    
</nav>

        </div>
    </div>



                    
                        <!-- Overlay For Active Sidebar -->
<div class="sidebar-overlay"></div>

<!-- Material sidebar -->
<aside id="sidebar" class="sidebar sidebar-colored sidebar-fixed-left" role="navigation">
    <div id="sidebar-main">
        <!-- Sidebar Header -->
        <div class="sidebar-header header-cover" style="background-image: url(/img/bg1.jpg);">
    <!-- Top bar -->
    <div class="top-bar"></div>

    <!-- Sidebar toggle button -->
    <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display: initial;" data-upgraded=",MaterialButton,MaterialRipple">
        <i class="material-icons">clear_all</i>
        <span class="mdl-button__ripple-container">
            <span class="mdl-ripple">
            </span>
        </span>
    </button>

    <!-- Sidebar Avatar -->
    <div class="sidebar-image">
        <img src="/img/selfie5.jpg" alt="eickEe's avatar">
    </div>

    <!-- Sidebar Email -->
    <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">
        eick2e@gmail.com
        <b class="caret"></b>
    </a>
</div>


        <!-- Sidebar Navigation  -->
        <ul class="nav sidebar-nav">
    <!-- User dropdown  -->
    <li class="dropdown">
        <ul id="settings-dropdown" class="dropdown-menu">
            
                <li>
                    <a href="#" target="_blank" title="Email Me">
                        
                            <i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">email</i>
                        
                        Email Me
                    </a>
                </li>
            
        </ul>
    </li>

    <!-- Homepage -->
    
        <li id="sidebar-first-li">
            <a href="/">
                
                    <i class="material-icons sidebar-material-icons">home</i>
                
                主页
            </a>
        </li>
        
    

    <!-- Archives  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">inbox</i>
                
                    归档
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
            <li>
                <a class="sidebar_archives-link" href="/archives/2018/07/">七月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/06/">六月 2018<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/05/">五月 2018<span class="sidebar_archives-count">1</span></a>
            </ul>
        </li>
        
    

    <!-- Categories  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">chrome_reader_mode</i>
                
                分类
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
                <li>
                <a class="sidebar_archives-link" href="/categories/Deep-Learning/">Deep_Learning<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/Machine-Learning/">Machine_Learning<span class="sidebar_archives-count">4</span></a>
            </ul>
        </li>
        
    

    <!-- Pages  -->
    

    <!-- Article Number  -->
    
</ul>


        <!-- Sidebar Footer -->
        <!--
I'm glad you use this theme, the development is no so easy, I hope you can keep the copyright, I will thank you so much.
If you still want to delete the copyrights, could you still retain the first one? Which namely "Theme Material"
It will not impact the appearance and can give developers a lot of support :)

很高兴您使用并喜欢该主题，开发不易 十分谢谢与希望您可以保留一下版权声明。
如果您仍然想删除的话 能否只保留第一项呢？即 "Theme Material"
它不会影响美观并可以给开发者很大的支持和动力。 :)
-->

<!-- Sidebar Divider -->

    <div class="sidebar-divider"></div>


<!-- Theme Material -->


<!-- Help & Support -->
<!--

-->

<!-- Feedback -->
<!--

-->

<!-- About Theme -->
<!--

-->

    </div>

    <!-- Sidebar Image -->
    

</aside>

                    

                    
                        <!-- Footer Top Button -->
                        <div id="back-to-top" class="toTop-wrap">
    <a href="#top" class="toTop">
        <i class="material-icons footer_top-i">expand_less</i>
    </a>
</div>

                    

                    <!--Footer-->
<footer class="mdl-mini-footer" id="bottom">
    
        <!-- Paradox Footer Left Section -->
        <div class="mdl-mini-footer--left-section sns-list">
    <!-- Twitter -->
    

    <!-- Facebook -->
    

    <!-- Google + -->
    

    <!-- Weibo -->
    

    <!-- Instagram -->
    

    <!-- Tumblr -->
    

    <!-- Github -->
    

    <!-- LinkedIn -->
    

    <!-- Zhihu -->
    

    <!-- Bilibili -->
    

    <!-- Telegram -->
    
    
    <!-- V2EX -->
    
</div>


        <!--Copyright-->
        <div id="copyright">
            Copyright&nbsp;©<script type="text/javascript">var fd = new Date();document.write("&nbsp;" + fd.getFullYear() + "&nbsp;");</script>eickEe
            
        </div>

        <!-- Paradox Footer Right Section -->

        <!--
        I am glad you use this theme, the development is no so easy, I hope you can keep the copyright.
        It will not impact the appearance and can give developers a lot of support :)

        很高兴您使用该主题，开发不易，希望您可以保留一下版权声明。
        它不会影响美观并可以给开发者很大的支持。 :)
        -->

        <div class="mdl-mini-footer--right-section">
            <div>
                <div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div>
                <div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div>
            </div>
        </div>
    
</footer>


                    <!-- Import JS File -->

    <script>lsloader.load("lazyload_js","/js/lazyload.min.js?1BcfzuNXqV+ntF6gq+5X3Q==", true)</script>



    <script>lsloader.load("js_js","/js/js.min.js?V/53wGualMuiPM3xoetD5Q==", true)</script>



    <script>lsloader.load("np_js","/js/nprogress.js?pl3Qhb9lvqR1FlyLUna1Yw==", true)</script>


<script type="text/ls-javascript" id="NProgress-script">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    $('#nprogress .bar').css({
        'background': '#29d'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #29d, 0 0 15px #29d'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#29d',
        'border-left-color': '#29d'
    });
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script>







    <!-- Busuanzi -->
    <script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



   





<!-- UC Browser Compatible -->
<script>
	var agent = navigator.userAgent.toLowerCase();
	if(agent.indexOf('ucbrowser')>0) {
		document.write('<link rel="stylesheet" href="/css/uc.css">');
	   alert('由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。');
	}
</script>

<!-- Import prettify js  -->

    
        
            <script>lsloader.load("prettify_js","/js/prettify.min.js?WN07fivHQSMKWy7BmHBB6w==", true)</script>
        
    



<!-- Window Load -->
<!-- add class for prettify -->
<script type="text/ls-javascript" id="window-load">
    $(window).on('load', function() {
        // Post_Toc parent position fixed
        $('.post-toc-wrap').parent('.mdl-menu__container').css('position', 'fixed');
    });

    
        
            $(function() {
                $('pre').addClass('prettyprint linenums').attr('style', 'overflow:auto;');
                prettyPrint();
                })
        
    
    
</script>

<!-- MathJax Load-->


<!-- Bing Background -->


<script type="text/ls-javascript" id="lazy-load">
    // Offer LazyLoad
    queue.offer(function(){
        $('.lazy').lazyload({
            effect : 'show'
        });
    });

    // Start Queue
    $(document).ready(function(){
        setInterval(function(){
            queue.execNext();
        },200);
    });
</script>

<!-- Custom Footer -->



<script>
    (function(){
        var scriptList = document.querySelectorAll('script[type="text/ls-javascript"]')

        for (var i = 0; i < scriptList.length; ++i) {
            var item = scriptList[i];
            lsloader.runInlineScript(item.id,item.id);
        }
    })()
console.log('\n %c © Material Theme | Version: 1.5.2 | https://github.com/viosey/hexo-theme-material %c \n', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-left-radius:5px;border-bottom-left-radius:5px;', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-right-radius:5px;border-bottom-right-radius:5px;');
</script>

                </main>
            </div>
        </body>
    
</html>
