<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>第三章 Training Model</title>
      <link href="/2018/07/09/ml-chapter3/"/>
      <url>/2018/07/09/ml-chapter3/</url>
      <content type="html"><![CDATA[<p>上一章中总结了一个完整的从数据下载到预处理到最后模型评价的过程，其中模型的训练部分事实上只有一行，fit()。用着当然是方便，不过这后面的训练方式确是多种多样又蕴含“人生哲理”的，在这章总结了两种（事实上主要是后一种）主要的模型训练的方法，后一种gradient descent也是最近大热的deep learning的训练参数的基础。</p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><p>There are two approaches for training parameters: <strong>Closed-form</strong>, <strong>Gradient descent</strong>.</p><h2 id="1-Closed-form"><a href="#1-Closed-form" class="headerlink" title="1. Closed-form"></a>1. Closed-form</h2><p>Using a direct “closed-form” equation (math equation) that directly computes the model parameters that best fit the model to the training set.</p><h3 id="1-1-Linear-regression"><a href="#1-1-Linear-regression" class="headerlink" title="1.1 Linear regression"></a>1.1 Linear regression</h3><ul><li><strong>Cost function</strong>:<br>$$loss=||X\beta-y||^2$$</li><li><strong>Minimize the cost function</strong>:<br>$$\hat{\beta}=argmin_\beta||X\beta-y||^2$$</li><li><strong>Closed form equation</strong>:<br>$$\hat{\beta}=(X^TX)^{-1}X^Ty$$</li></ul><p>– 第一种方法就是Closed-form，用数学的公式直接计算（这里是一个最小二乘法的例子），好处显而易见，一步到位，直接得到理想参数。缺点嘛，自然也是明显的，一方面，要找到合适的closed form solution是极其困难的，模型也是多种多样。其次，即使是Linear regression的closed form solution，在面对高维度的特征量时，训练速度也会大幅度下降。<br>这时候，就需要另一个思路的解决方法了，也就是另一位带头带哥来了—“GD”。当然，这里不是在说G-dragon，而是Gradient Descent，梯度下降。</p><h2 id="2-Gradient-Descent-in-Linear-Regression"><a href="#2-Gradient-Descent-in-Linear-Regression" class="headerlink" title="2. Gradient Descent in Linear Regression"></a>2. Gradient Descent in Linear Regression</h2><p>Gradient Descent is a very generic optimization algorithm capable of finding  optimal solution to a wide range of problems. The general idea of Gradient Descent is to tweak parameters iteratively in order to minimize a cost function.</p><p>进入正题前，先唠叨几句：</p><ul><li>我个人的理解一些梯度下降法（准确的是在说 Gradient-based 不只是GD）的重要性：<ul><li>直接的一点就是，解决了模型最优化（训练）的问题，且具有模型普适性（只要其cost function得当）；</li><li>解决了内存不足的问题，可分batch训练；</li><li>带来了online learning的可行性（原因同2）；</li></ul></li><li>这章主要是针对Linear 和Logistic Regression来讲述GD的，其他模型的思路大体相同；</li><li>基于gradient的方法不止GD一种，也包括高斯牛顿法等，这章就不整理了哈；</li><li>这章将整理几种基础GD的方式，后面针对于Nerual Network的GD的优化（如Adam等）会整理在后面的Deep learning篇里；</li><li>这里同样分享一个大牛的Post，也是专门讲解Gradient Descent的：<a href="http://ruder.io/optimizing-gradient-descent/index.html" target="_blank" rel="noopener">http://ruder.io/optimizing-gradient-descent/index.html</a></li></ul><p>简单的说梯度下降，</p><ul><li>如同之前的最小二乘法，运用上一章提到的如MSE等方式建立一个Cost Function，这个Function的值越小，证明模型越理想。GD的目的就是一步一步去调整各个参数的值，慢慢寻找到使得function最小的参数们的值。</li><li>举个例子，假设Cost function的形状是一座山，这个寻找的过程，有点像从这个山上的一个位置下山（假设参数量是2维的），起始点（参数的初始化决定）开始要找下山的方向，这里的方向也就是负梯度（负导数）的方向，走一段（沿这个方向走的距离又由learning rate决定），然后掏出地图（再次求导）看看下山的方向，重复，直到走到山底。当然这个比较理想化，也可能是一个山腰，但由于我们不敢迈大步子，所以找不到更低的路。（存在Local minimum）</li></ul><p>接下来，详细整理下这个下山的各个环节。</p><h3 id="2-1-Learning-Rate"><a href="#2-1-Learning-Rate" class="headerlink" title="2.1 Learning Rate"></a>2.1 Learning Rate</h3><ul><li>Decide the <strong>size of steps</strong>:<div align="center"><br><img src="/img/chapter3/2.1.1.png" width="350" hegiht="200" align="center"><br></div></li><li><strong>Not all</strong> the cost function look like nice regular bowls. There may be holes, ridges plateaus, etc.<br><div align="center"><br><img src="/img/chapter3/2.1.2.png" width="350" hegiht="200" align="center"><br></div><br>这里就是刚刚提到的步子迈太大或太小以及存在半山腰所带来的问题                </li><li>Shape of cost function could be an elongated bowl if the features have very <em>different scales</em>:<br><div align="center"><br><img src="/img/chapter3/2.1.3.png" width="400" hegiht="200" align="center"><br></div><br><em>Using Gradient Descent, you should ensure that all features have a <strong>similar scale</strong> by StandardScaler class.</em><br>这里解释了需要做scaling原因，梯度下降都会沿着这一区域下降最快的方向，所以如果出现图1中的情况，显然，每个局部的最佳不代表整体的最佳方向，所以要做scaling。</li></ul><h3 id="2-2-Batch-Gradient-Descent"><a href="#2-2-Batch-Gradient-Descent" class="headerlink" title="2.2 Batch Gradient Descent"></a>2.2 Batch Gradient Descent</h3><ol><li><strong>Partial derivative of cost function</strong>:<ul><li>Cost Function(MSE)</li><li>Partial derivative of MSE at feature j:<br>$$\frac{\partial MSE(\theta)}{\partial \theta_j}=\frac{2}{m}\sum_{i=1}^m (\theta^T\cdot x^{(i)}-y^{(i)})x^{(i)}_j$$</li></ul></li><li><strong>Gradient Vector</strong>:<br>$$\nabla_\theta MSE(\theta)=\left(<br>\begin{matrix}<br>\frac{\partial}{\partial_0}MSE(\theta) \newline<br>\frac{\partial}{\partial_1}MSE(\theta) \newline<br>… \newline<br>\frac{\partial}{\partial_n}MSE(\theta) \newline<br>\end{matrix}\right)=\frac{2}{m}X^T\cdot(X\cdot\theta -y)$$<br> <em>It uses the  whole batch of training data at every step.</em></li><li><strong>Gradient Descent Step</strong>:<br>$$\theta^{(next step)} = \theta-\eta\nabla_\theta MSE(\theta)$$<br><em>- Use grid search to find good learning rate;</em><br><em>- Interrupt the algorithm when the gradient vector becomes tiny.</em></li></ol><pre><code class="py">import numpy as npn_epoch = 50 #迭代次数，一个epoch是走完一整个数据集eta = 0.1    #learning ratem = 100      #数据总数def batch_gradient_descent(n_epoch, X, y, m):    theta = np.random.randn(2,1)                               #初始化参数    for epoch in range(n_epcoh):        gradients = 2/m * X.T.dot(X.dot(theta)-y)            #计算整个batch的导数        theta = theta - eta * gradients                     #梯度下降    return theta</code></pre><p>这里简单的实现了一下Batch Gradient Descent，首先用MSE建立cost function，第一步的负偏导数也就是找各个参数的下降方向（这里因为是Batch的方法，所以计算参考了每个数据（m），然后做了一个平均），平均后也就得到后一步的Gradient Vector，乘上eta（learning rate），让参数们加上这个变化量就行了（是不是简单明了（滑稽脸））。<br>然而，一个问题出现了，每次算方向，岂不是都要一口气把整个batch送进去算（所以数据）？对的，所以时间和内存代价就来了。然后就出现了接下来这种stochastic的方法。</p><h3 id="2-3-Stochastic-Gradient-Descent"><a href="#2-3-Stochastic-Gradient-Descent" class="headerlink" title="2.3 Stochastic Gradient Descent"></a>2.3 Stochastic Gradient Descent</h3><p>SGD just picks a random instance in the training set at every step and computes the gradients based only on that single instance.</p><div align="center"><br><img src="/img/chapter3/2.3.png" width="400" hegiht="200" align="center"><br></div><ul><li>It decreases only on average and ends up very close to the minimum;</li><li>The final parameter values are good, but not optimal;</li><li>It can help algorithm jump out of local minima;</li><li>The steps start out large, then get smaller and smaller( simulated annealing).</li></ul><pre><code class="py">n_epoch = 50t0,t1=5,50#这里稍微不同，由于随机的特点，做了一个简单learning rate的规划（越来越小）。def learning_schedule(t):    return t0/(t+t1)def stochastic_gradient_descent(n_epoch, X, y, m):    theta = np.random.randn(2,1)    for epoch in range(n_epcoh):        for i in range(m):            random_index = np.random.randint(m)            #随机选一个而不是全部            xi = X[random_index:random_index+1]            yi = y[random_index:random_index+1]                    gradients= 2*xi.T.dot(xi.dot(theta)-yi)            eta = learning_schedule(epoch * m + i)        #运用刚刚的learning规划            theta = theta - eta*gradients    return theta</code></pre><p>这里也简单的实现了这种方法，唯一的不同也就是把这个batch换成每次随机选一个。优缺点如上 ^ 。</p><h3 id="2-4-Mini-batch-Gradient-Descent"><a href="#2-4-Mini-batch-Gradient-Descent" class="headerlink" title="2.4 Mini-batch Gradient Descent"></a>2.4 Mini-batch Gradient Descent</h3><p>Mini-batch GD computes the gradients on small random sets of instances called mini-batches.</p><div align="center"><br><img src="/img/chapter3/2.4.png" width="400" hegiht="200" align="center"><br></div><ul><li>Get a performance boost from hardware optimization of matrix operations. Especially in GPUs;</li><li>Less erratic(不稳定)  than Stochastic GD<br>其实这种方法也就是综合一下前两种，既不全都也不单个，用一小块。其实，在machine learning的算法中，这种例子很多，比如还有后面的Elastic Net正则化的方法，比如在“未来”章节中的Adam最优化，毕竟站在巨人的肩膀上才是捷径嘛～</li></ul><h2 id="3-GD-in-Logistic-Regression"><a href="#3-GD-in-Logistic-Regression" class="headerlink" title="3. GD in Logistic Regression"></a>3. GD in Logistic Regression</h2><p>讲Logistic之前，先说两个GD中的两个技巧。</p><h3 id="3-1-Learning-curve"><a href="#3-1-Learning-curve" class="headerlink" title="3.1 Learning curve"></a>3.1 Learning curve</h3><p>These are plots of the model’s performance on the training set and the validation set as a function of the training set size(or iteration):</p><div align="center"><br><img src="/img/chapter3/3.1.png" width="400" hegiht="200" align="center"><br></div><ul><li>The learning curves are typical of an underfitting model. Both curves have reached a plateau, close and fairly high;</li><li>The gap between the curves is the hall-mark of an overfitting model.<br>Leraning curve的好处就在于既可以看到是否overfitting（两个线间的距离）又可以看到是否underfitting（两者在测试中的表现）</li></ul><h3 id="3-2-Regularized-Linear-Models"><a href="#3-2-Regularized-Linear-Models" class="headerlink" title="3.2 Regularized Linear Models"></a>3.2 Regularized Linear Models</h3><p>正则化（regularization）的思想简单的讲就是，在cost function中加入一个正则项来做penalty，防止其对训练数据集调整过度，导致的overfitting的问题。这里介绍了3种基本的正则项。<br>3 ways to constrain weights of model: <strong>Ridge Regression</strong>, <strong>Lasso Regression</strong>,<strong>Elastic Net</strong>.</p><ul><li><p><strong>Ridge Regression</strong>(Tikhonov regularization, L2)<br>A regression term l2 is added to the cost function:<br>$$J(\theta)=MSE(\theta)+\alpha\frac{1}{2}\sum_{i=1}^n{\theta_i^2}$$<br><em>It’s important to scale the data;</em></p></li><li><p><strong>Lasso Regression</strong>(L1)<br>  A regression term l1 is added to the cost function:<br>$$J(\theta)=MSE(\theta)+\alpha\frac{1}{2}\sum_{i=1}^n{|\theta_i|}$$    </p><ul><li>An important characteristic of Lasso Regression is that it tends to completely eliminate the weights of the weights of the least important features;</li><li>Lasso Regression automatically performs feature selection and outputs a sparse model;</li><li>Lasso Regression is not differentiable at 0, so use a subgradient vector g when any weights=0.<br>$$g(\theta,J)=\nabla_\theta MSE(\theta)+\alpha\left(<br>\begin{matrix}<br>sign(\theta_1) \newline<br>sign(\theta_2) \newline<br>… \newline<br>sign(\theta_n) \newline<br>\end{matrix}<br>\right) \text{where} \ sign(\theta_i)=<br>\begin{cases}<br>-1, &amp; \text{if $ \ \theta_i&lt;0$} \newline<br>0, &amp; \text{if $ \ \theta_i=0$} \newline<br>+1, &amp; \text{if $ \ \theta_i&gt;0$} \newline<br>\end{cases}<br>$$</li><li><strong>Comparison</strong> of Ridge and Lasso:<br><div align="center"><br><img src="/img/chapter3/3.2.1.png" width="400" hegiht="200" align="center"><br></div>        <ul><li>L1 tends to screen the features(also against the overfitting), and L2 tends to avoid the overfitting.</li><li>书中对这张图的说明并不是很充分，这里给出我的几个对于L1和L2的见解：<ul><li>比较权威的解释为何对比l2，l1会更倾向优先筛选特征，形成一个稀疏矩阵。可以参考<a href="https://blog.csdn.net/qq_34531825/article/details/52689654" target="_blank" rel="noopener">https://blog.csdn.net/qq_34531825/article/details/52689654</a> 这篇文章，主要的思想就是在几何图形上找出正则项和原Cost Function的交点，由于l1的几何图形为菱形的特点，交点大部分坐落在坐标轴上。原文考虑的很周全，详情参考原文，<div align="center"><br><img src="/img/chapter3/3.2.3.png" width="400" hegiht="200" align="center"><br><br><br></div>    </li><li>其实吧，我也有一种自己的想法（仅个人意见），只看正则项的图形的话：左上的l1对比左下的l2优先接近某一坐标轴，也就是间接优先使得一项参数归0，这也就是为什么有了“筛选”这一功能。这一点可以通过两个正则项的形状来解释，l1由于绝对值的计算，图像倾向于一个菱形，而l2则是椭圆，从最优下降方向来讲，自然是l1沿着棱形边的垂直角度，所以大部分的可能会优先去接近于某个坐标轴，而相比棱形的椭圆则是可能会接近但不会交于某个坐标轴。</li><li>所以从上面的角度也可以讲，l1一般的情况下，下降速度要快于l2。</li><li>当然，这样一说岂不是l1美滋滋，l2滚出克了嘛？回答当然是no了。l2的好处是很多的。其一，最明显的就是，l2每个地方都可导，实现比较方便。再者，l2可以很好处理condition number不好导致的求逆矩阵困难的问题，这个在此不做扩展了，详情可以看一下<a href="http://pengshuang.space/2017/03/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84L1-%E5%92%8C-L2/" target="_blank" rel="noopener">http://pengshuang.space/2017/03/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84L1-%E5%92%8C-L2/</a></li><li>总结呢，一句话好了，l1倾向于平滑参数，l2倾向于筛选。</li></ul></li></ul></li></ul></li><li><p><strong>Elastic Net</strong><br>  This is middle ground between Ridge Regression and Lasso Regression. The regularization term is a simple mix of both L1 and L2.<br>  $$J(\theta)=MSE(\theta)+r\alpha\sum_{i=1}^m|\theta_i|+\frac{1-r}{2}\alpha\sum_{i=1}^m\theta_i^2$$<br>  如上面讲的，综合一哈就完事了～                </p></li><li><strong>Early Stopping</strong><br>This is method which try to stop training as soon as the validation error reaches a minimum.<br><div align="center"><br><img src="/img/chapter3/3.2.2.png" width="400" hegiht="200" align="center"><br></div><br>这个方式是非常直接的减少overfitting问题的方法，实现简单，效果拔群。好了，接下来进入正题吧。</li></ul><h3 id="3-3-Logistic-Regression"><a href="#3-3-Logistic-Regression" class="headerlink" title="3.3 Logistic Regression"></a>3.3 Logistic Regression</h3><p>Logistic Regression is commonly used to estimate the probability that an instance belongs to a particular class.<br>加一点自己的理解：</p><ul><li>Logistic R和Linear R都是一种Generalized linear model，只不过Logistc Regression（这里简称LR）是吧Linear R的结果输入进一个预测函数（sigmoid）。其一，Sigmoid函数引入了非线性因素。其二，sigmoid函数讲结果输出在（0，1）。这样可以轻松处理（0 or 1）的二分类问题。（这里的0～1不是概率，而是一种可能性）</li><li><p>插个题外话，其实get到了LR，也就get到了Nerual Network中的neruon的概念，LR就可以当作一个neruon来看待，只不过这里用的是sigmoid作为activive function。</p></li><li><p><strong>Estimating Probabilities</strong>:</p><ul><li>Logistic Regression also computes a weighted sum of the input features( with a bias term), and outputs the logistic of this result:<br>$$\hat{p}=h_\theta(x)=\sigma(\theta^T\cdot x)$$</li><li>Logistic function ( sigmoid function):<br>$$\sigma(t)=\frac{1}{1+e^{-t}}$$<div align="center"><br><img src="/img/chapter3/3.3.png" width="400" hegiht="200" align="center"><br></div></li></ul></li><li><p><strong>Training and Cost Function</strong></p><ul><li>在上一小节，我们对Linear R用MSE来作为cost function，然而这招对于LR不太成，我们看一下，假设我们继续MSE的话，LR的cost fucntion就会变成这个样子（copy个图，有空自己重新补个）：<br><div align="center"><br><img src="https://camo.githubusercontent.com/bde8204ff85b0b35fe8992d385e171af3e4ee30a/687474703a2f2f35326f70656e636f757273652e636f6d2f3f71613d626c6f622671615f626c6f6269643d363037343335323935303439373831373235" width="300" hegiht="200" align="center"><br><br><br></div><br>显然，存在了local minimum，因此，单纯的用MSE在LR这是行不通的，所以就有下面的Cost function</li><li><p>Cost function of a single training instance:<br>$$c(\theta)=<br>\begin{cases}<br>-\log(\hat{p}), &amp; \text{if y=1} \newline<br>-\log(1-\hat{p}), &amp; \text{if y=0} \newline<br>\end{cases}$$</p></li><li><p>Logistic Regression cost function:<br>$$J(\theta)=-\frac{1}{m}\sum_{i=1}^m[y^{(i)}\log(\hat{p}^{(i)})+(1-y^{(i)})\log(1-\hat{p}^{(i)})]$$</p></li><li>Partial derivatives:<br>$$\frac{\partial}{\partial\theta_j}J(\theta)=-\frac{1}{m}\sum_{i=1}^m(\sigma(\theta^T\cdot x^{(i)})-y^{(i)})x_j^{(i)}$$</li><li>公式简洁明了，书中没有具体解释这，这里有多种解释的方式，我尽力总结，水平有限，欢迎指正。<ul><li>第一种简单明了的方式，可以直接公式字面意义上理解，取对数是为了方便后面偏导数，单调性并没有改变，结果越接近样本本身的label的话，cost function值越小。当然，这不严谨（岂止不严谨ㅋㅋㅋㅋㅋㅋ），所以严谨的来了，最大似然估计。</li><li>实时上，linear R也可以通过最大似然来推出cost function，这里就不做整理了，推荐个详细的post：<a href="http://www.hanlongfei.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/08/05/mle/" target="_blank" rel="noopener">http://www.hanlongfei.com/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2015/08/05/mle/</a> 。ok，回到LR，简单的来推一下，把LR想成一个二项分布（LR模型就建立在“样本分类标签满足二项分布”的假设上），那么：<br>$$P(\hat{y}^{(i)}=1|x^{(i)};\theta) = h_{\theta}(x^{(i)})$$<br>$$P(\hat{y}^{(i)}=0|x^{(i)};\theta) = 1-h_{\theta}(x^{(i)})$$<br>求得的似然函数则为：<br>$$L=\prod_{i=1}^mP(\hat{y}^{(i)}=1|x^{(i)})^{\hat{y}(i)}\cdot P(\hat{y}^{(i)}=0|x^{(i)})^{(1-\hat{y}(i))}$$<br>这里的h（x）就是LR的预测函数，然后取个对数，单调性不变：<br>$$L=\sum_{i=1}^m[\hat{y}^{(i)}\log(h_{\theta}(x^{(i)}))+(1-\hat{y}^{(i)})\log(1-h_{\theta}(x^{(i)}))]$$<br>厉害了，是不是已经很像了？求最大似然，也就是求取-L的最小值，在平均一下：<br>$$J(\theta)=-\frac{1}{m}\sum_{i=1}^m[\hat{y}^{(i)}\log(h_{\theta}(x^{(i)}))+(1-\hat{y}^{(i)})\log(1-h_{\theta}(x^{(i)}))]$$<br>成了，cost function搞定，至于偏导后那么简洁几乎和Linear R一样的梯度参数，其实就是带入求导，我之前在纸上尝试过，就是过程比较繁琐，不算上矩阵求偏导，基本就是高中导数题，这里就不做整理了。</li><li>当然，也可以像后面的softmax一样，用交叉熵（cross entropy）的思想来解释，这里就需要信息熵、信息量等概念，一会具体解释。</li></ul></li></ul></li></ul><h3 id="3-4-Softmax-Regression"><a href="#3-4-Softmax-Regression" class="headerlink" title="3.4 Softmax Regression"></a>3.4 Softmax Regression</h3><p>Logistic Regression model can be generalized to support multiple classes directly which is called Softmax Regression or Multinomial Logistic Regression.<br>直白的理解就是扩展了LR，不止可以分类两种。正因如此，Softmax的损失函数依然可以通过上面的方法理解和推倒。</p><ul><li><strong>Compute Softmax score for class k</strong>:<br>$$s_k(x)=\theta_k^T\cdot x$$</li><li><strong>Softmax function</strong>:<br>$$\hat{p}_k=\sigma(s(x))_k=\frac{e^{s_k(x)}}{\sum_{j=1}^ke^{s_j(x)}}$$</li><li><strong>Classifier prediction</strong>:<br>$$\hat{y}=argmax_k\sigma(s(x))_k=argmax_k s_k(x)=argmax_k(\theta_k^T\cdot x)$$<br><em>Softmax Regression predicts only one class at a time( can not recognize multiple people in one picture).</em></li><li><strong>Cross entropy cost function</strong>:<br>$$J(\Theta)=-\frac{1}{m}\sum_{i=1}^m\sum_{k=1}^K y_k^{(i)}\log(\hat{p}_k^{(i)})$$<br>这里插一句，在LR中，我们最后提到了可以用交叉熵来解释损失函数，这点在Softmax中更加明显。简单的讲就是运用真实分布来衡量预测结果，内容比较多，找个时间在写篇小的总结。</li><li><strong>Cross entropy gradient vector for class k</strong>:<br>$$\nabla_{\theta_k}J(\Theta)=\frac{1}{m}\sum_{i=1}^m(\hat{p}_k^{(i)}-y_k^{(i)})x^{(i)}$$</li></ul><p>好了，终于。这章的内容真是，越写越多，能扩展的东西也很多很多，有机会就小补一下。<br>下一章有点纠结是继续Machine learning基础的model还是直接复习Deep Learning了，反正都是坑555</p>]]></content>
      
      <categories>
          
          <category> Machine_Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Gradient Descent </tag>
            
            <tag> 模型训练 </tag>
            
            <tag> Logistic Regression </tag>
            
            <tag> L1,L2 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>第二章 一个 “End to End Project” 的例子</title>
      <link href="/2018/06/22/ml-chapter2/"/>
      <url>/2018/06/22/ml-chapter2/</url>
      <content type="html"><![CDATA[<p>这一章的内容我将书中的第二章和第三章的内容进行了整合（原为一个预测房价的的例子（回归）和识别图中手写数字的例子（分类））。<br>代码部分则为通用版本，主要为使用方法，需要具体问题具体使用。整个一章的内容包含数据预处理，使用模型训练和模型调超参和预测，以及模型评估。</p><p>编程部分选用python3（实际上对于编程水平没有过多的要求），以及pandas，numpy，sklearn等库，这里就不说怎么配置配置环境了（pip很快就搞定了）。书中推荐了Jupyter作为workspace（毕竟是赞助），实测还是可以，配置简单。不过这个东西大家就仁者见仁了, 用自己喜欢的就好.</p><p>这章结束后，推荐可以做一些kaggle里比较基础的比赛来走走流程，比如Titanic那个通过乘客信息预测是否丧生的项目。<a href="https://www.kaggle.com/c/titanic" target="_blank" rel="noopener">https://www.kaggle.com/c/titanic</a></p><p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p><h2 id="一些背景知识"><a href="#一些背景知识" class="headerlink" title="一些背景知识"></a>一些背景知识</h2><h3 id="1-Pipeline"><a href="#1-Pipeline" class="headerlink" title="1. Pipeline"></a>1. Pipeline</h3><p>Pipeline is a sequence of data processing components which there is a lot of data to manipulate and many data transformations.(Asynchronously)</p><p>概念上讲Pipeline：将一个重复做的事情分为几个阶段，每个阶段由不同单元完成（例如，预处理（可包含多个阶段），训练等），所有执行对象（training data），排好队一次进入服务，除了开始和结尾一段时间，任何时刻各个单元都在同时工作。</p><div align="center"><br><img src="/img/chapter2/pipline.png" width="400" hegiht="200" align="center"><br><br><br></div><h3 id="2-RMSE-Root-Mean-Square-Error-MSE-MAE-Mean-Absolute-Error"><a href="#2-RMSE-Root-Mean-Square-Error-MSE-MAE-Mean-Absolute-Error" class="headerlink" title="2. RMSE(Root Mean Square Error)/MSE/MAE(Mean Absolute Error)"></a>2. RMSE(Root Mean Square Error)/MSE/MAE(Mean Absolute Error)</h3><ul><li><strong>RMSE computes the root of a sum of squares corresponds to the Euclidian norm:</strong>            </li></ul><p>$$MSE=\frac{1}{N}\sum_{t=1}^N {(observed_t-predicted_t)}^2$$<br>$$RMSE=\sqrt{\frac{1}{N}\sum_{t=1}^N {(observed_t-predicted_t)}^2}$$</p><ul><li><strong>MAE measures distance between 2 points:</strong>                    </li></ul><p>$$MAE=\frac{1}{N}\sum_{t=1}^N {|observed_t-predicted_t|}$$</p><p>– RMSE is more sensitive to the outliers(for square compute) than the MAE, but when outliers are exponentially rare, RMSE performs well and is generally preferred.</p><p>这一部分一般用作表示结果与实际值的误差（也就是 Performance Measurement），或者可以以此为基础建立cost fucntion用于后面的gradient descent等。（当然构成cost function的计算方式有很多种，不局限于此，例如交叉熵等）</p><h2 id="End-to-End-Project"><a href="#End-to-End-Project" class="headerlink" title="End to End Project"></a>End to End Project</h2><h3 id="1-Steps-of-Data-Preprocessing"><a href="#1-Steps-of-Data-Preprocessing" class="headerlink" title="1. Steps of Data Preprocessing"></a>1. Steps of Data Preprocessing</h3><h4 id="Step-of-the-fetching-out"><a href="#Step-of-the-fetching-out" class="headerlink" title="Step of the fetching out"></a>Step of the fetching out</h4><ol><li><strong>About data fetching out</strong><br>这里提供了通过url直接下载数据的方式，其实手动也是可以，最终目的都是得到csv的数据文件。然后通过pandas库进行数据的读取。  </li></ol><pre><code class="py">import osimport tarfilefrom six.moves import urllibdef fetch_data (url, path):    if not os.path.isdir(path):        os.makedirs(path)    tgz_path = os.path.join(&quot;datasets&quot;, &quot;housing&quot;)    urllib.request.urlretrieve(url, tgz_path)    data_tgz = tarfile.open(tgz_path)    data_tgz.extractall(path = path)    data_tgz.close()import pandas as pddef load_data(path):    csv_path = os.path.join(path, &quot;data.csv&quot;)    return pd.read_csv(csv_path)</code></pre><ol start="2"><li><strong>Do nothing about the test data for the data snooping bias.(select the algorithm optimistically)</strong><br> 这里预先把testing set拿出防止选择模型和调参期间对最后的testing过程具有偏向性（snooping bias）。</li></ol><pre><code class="py">import numpy as npdef split_train_test(data, ratio):    shuffled_indices = np.random.permutation(len(data)) #打乱顺序    test_set_size = int(len(data)*ratio)    test_indices = shuffled_indices[:test_set_size]    train_indices = shuffled_indices[test_set_size:]    return data.iloc[train_indices], data.iloc[test_indices] # 读打乱后的index</code></pre><ol start="3"><li><strong>To generate the test group without any traning data previously used, set identifier to each instance.</strong><br> 比如，，可以给每个instance设置个identifier，然后用hash函数来来分别计算data的identifier来进行分配，保证即使每次刷新data set后，test set 也不会包含之前training过的数据。</li></ol><pre><code class="py">import hashlibdef test_set_check(identifier, ratio, hash):    return hash(np.int64(identifier)).digest()[-1]&lt;256*ratiodef split_train_test_by_id(data, ratio, id_columm, hash = hashlib.md5):    id = data[id_column]    in_test_set = id.apply(lambda id_: test_set_check(id_, ratio, hash))    return data.loc[~in_test_set], data.loc[in_test_set]data_with_id = data.reset_index()train_set, test_set = split_train_test_by_id(data, 0.2, &quot;index&quot;, hash = hashlib.md5)</code></pre><ol start="4"><li><strong>The Sampling Bias (there are original strata in the data fetching step). To do the  stratified sampling,  use the StratifiedShuffleSplit class.</strong><br> 例如，我们要在一个城市通过个人的一些个人信息来预测他的职业，其中一点，要考虑到原有的男女分布，也就是这里的original strata，为了防止分组是破坏了原有的阶层分布，需要按照固定的strata来进行分组。</li></ol><pre><code class="py">import sklearn.model_selection import StratifiedShuffleSplitsplit = StratifiedShuffleSplit(n_splits=1, test_size, random_state=42)for train_index, test_index in split.split(data, data[&quot;stratified_attribute&quot;])    strat_train_set = data.loc(train_index)    strat_test_set = data.loc(test_index)</code></pre><ol start="5"><li><strong>Looking for correlations: Use the corr() to compute the standard correlation coefficient.(close to 0 means no linear correlation)After selecting the machine learning algorithm we can compute the correlation by that algorithm again.</strong><br> 例如我训练了一个简单的决策树，那么在此做correlation比对的时候，可以选择这个训练后的决策树进行相关性分析。因为原corr()只能列出linear correlations.</li></ol><pre><code class="py">corr_martrix = data.corr() #http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html 这是 corr()的文档，可以看到原默认的method有四种。&gt;&gt;&gt; corr_matrix[&quot;predict_attribute&quot;].sort_values(ascending =False) #这里通过给出的目标attribute来列出各项和它的相关系数。</code></pre><ol start="6"><li><strong>Attribute Combination: Create new attribute by the existed ones.</strong><br> 在上一章了提到了这个一部分，产生新的attribute的方法有很多，一些分类器也提供了相关的kernel来帮我们解决了一部分这个问题。但从我个人的经验，如果我们可以找到一种更靠谱的rule去产生更靠谱的attribute（这里可以尝试用前面的corr()方法来暂时验证一下），然后配合不同的kernel可能会得到更好的结果，因为kernel还是主要解决线性不可分的问题。</li></ol><h4 id="Step-of-the-preparing"><a href="#Step-of-the-preparing" class="headerlink" title="Step of the preparing"></a>Step of the preparing</h4><ol><li><strong>Separate the features and the labels and do the copies.</strong><br> 做个备份以防万一～</li><li><strong>Do the fixing for missing features by Imputer class</strong><ul><li>Get rid of the corresponding districts;</li><li>Get rid of the whole attribute;</li><li>Set the values to some value(Zero, the mean or the median, etc.)<br><em>if use the mean value for fixing, remember to save the value for the test dataset.</em><br>这里给了两种方式</li></ul></li></ol><pre><code class="py">#简单直接式，但需要保存下来对应值，方便后面对test进行相同操作#option1data.dropna(subset=[&quot;fixed_attribute&quot;])#option2data.drop(&quot;fixed_attribute&quot;, axis=1)#option3 用了median，当然也可以mean或zeromedian = housing[&quot;fixed_attribute&quot;].median()data[&quot;fixed_attribute&quot;].fillna(median, inplace=True)</code></pre><pre><code class="py">#引用Imputer对象，一劳永逸式, 以median为例子import sklearn.preprocessing import Imputerimputer = Imputer(strategy=&quot;median&quot;)#书中用的加利福尼亚房价的例子里包含了text attribute，所以计算中值前需要提前drop掉data_numercial = data.drop(&quot;text_attribute&quot;, axis=1)imputer.fit(data_numercial)&gt;&gt;&gt; data_numercial.median().values#这样就可以看到各个特征值中值了#接着填坑了data_fixed = imputer.transform(data_numercial) #这里的data_fixed是一个Numpy Array#我自己的想法，这里用imputer也是方便后面对test set用同一个trained好的imputer对象来填空，就省去自己去保留填补的值这一步骤。</code></pre><ol start="3"><li><strong>Handling Text and Categorical Attributes with factorize()</strong> </li></ol><ul><li>较简单的factorize的方式（这种方法只是单纯的对应种类编号，不推荐）</li></ul><pre><code class="py">data_cat_encoded, cat = data_cat_attribute.factorize()#第一个返回项是对一多个种类进行编号的后的数字化的特征值，第二个返回项是种类</code></pre><ul><li>One-hot encoding：<ul><li>Create one binary attribute per category(e.g. [1., 0., 0., 0.7]);</li><li>Zeros will be ignored, only nonzero elements will be stored(use toarray()  to see all)</li><li>这种做法的好处书中没有具体写，我个人的理解可以分为两点：<ul><li>生成一个稀疏矩阵，一些情况下会有助于加速训练速度</li><li>变相的增加了特征值（纬度），一些情况下会有助于后面处理非线性的问题</li></ul></li></ul></li></ul><pre><code class="py">#接着上面facterize后的特征值from sklearn.preprocessing import OneHotEncoderencoder = OneHotEncoder()data_cat_1hot = encoder.fit_transform(data_cat_encoded.reshape(-1,1)) #因为这个方法输入必须为2D的array#后体面还介绍了用CategoricalEncoder这个对象来直接作1hotencoding，但需要下载advanced版本的sklearn，这里就不多介绍了。</code></pre><ol start="4"><li><strong>Custom transformers: Design the custom transformer class for future use.</strong><br>这里就是把之前的一些处理方式做了一个custom class</li><li><strong>Feature Scaling:</strong> <ul><li>Normalization: effected by the min and max values, rescale the values into 0~1(easily effected by the outliers)</li><li>Standardization (less effects by outliers):<br>  1) Subtract the mean value;<br>  2) Divided by variance (results will hold the unit variance);</li><li>Scaling会造成很多问题，比如，会直接影响一些对scaling比较敏感的model的性能（比如SVM），对于Normalization的方法可以调用sklearn中的MinMaxScaler，Standardization则使用StandardScaler。</li></ul></li></ol><pre><code class="py">#Normalizationimport sklearn.preprocessing import MinMaxScalerminmax = MinMaxScaler()minmax.fit_transform(data[&quot;scale_attribute&quot;])</code></pre><pre><code class="py">#Standardizationimport sklearn.preprocessing import StandardScalerscaler = StandardScaler()scaler.fit(data[&quot;scale_attribute&quot;])scaler.transform(data[&quot;scale_attribute&quot;])#两种方法后面都可以直接调用相应对象来scaling后面的test set</code></pre><ol start="6"><li><strong>Make transformation pipeline with pipeline class:</strong><ul><li>fit() will calls the fit_transform() sequentially on  all transformers</li><li>Two pipeline could be combined in to a single one by the  FeatureUnion class.</li><li>结合前面的pipline，这里列了一个简单的例子，将预处理的不同步骤结合成一个完整的pipline；</li></ul></li></ol><pre><code class="py">#这里我们会处理的大部分pandas frame的data会包含一些非numercial的特征值，所以这里的做法是先定义了一个numercial特征值的提取器，然后写了两个pipeline分别针对两类特征值，最后在合并这两个pipline。#numercial特征提取器，必须包含fit，transform。from sklearn.base import BaseEstimator, TransformerMixin#选择器class DataFrameSelector(BaseEstimator, TransformerMixin):    def __init__(self, attribute_name):        self.attribute_names = attribute_names    def fit(self,X, y=None):        return self    def transform(self, X):        return X[self.attribute_names].valuesnum_attributes = list(data.drop(&quot;text_attribute&quot;,axis=1))cat_attributes = [&quot;text_attribute&quot;]#numercial类的piplinenum_pipline = Pipline([    (&#39;selector&#39;, DataFrameSelector(num_attributes)),    (&#39;imputer&#39;, Imputer(stratgy = &quot;median&quot;)),    (&#39;std_scaler&#39;, StandardScaler()),    ])#text类piplinecat_pipline = Pipline([    (&#39;selector&#39;, DataFrameSelector(cat_attributes)),    (&#39;cat_encoder&#39;, CategoricalEncoder(encoding = &quot;onehot-dense&quot;)),    ])#合并两种piplinefrom sklearn.pipline import FeatureUnionfull_pipline = FeatureUnion(transformer_list = [    (&quot;num_pipline&quot;, num_pipline),    (&quot;cat_pipline&quot;, cat_pipline),    ])#运用piplinepreprocessed_data = full_pipline(data)</code></pre><h3 id="2-Step-of-selecting-and-training-a-Model"><a href="#2-Step-of-selecting-and-training-a-Model" class="headerlink" title="2. Step of selecting and training a Model"></a>2. Step of selecting and training a Model</h3><ul><li><strong>Select and train a model.</strong><br>这部分后面章节会详细总结，这里暂时用个随机森林的例子（事实上，用sklearn库的话，model的调用和使用方式都是非常方便的）</li></ul><pre><code class="py">from sklearn.ensemble import RandomForestRegressorforest_reg = RandomForestRegressor() #调用随机森林模型forest_reg.fit(preprocessed_data,labels) #训练模型pre = forest_reg.predict(preprocessed_test_data) #通过训练的模型预测test data</code></pre><ul><li><strong>Evaluation with Cross-Validation</strong><br>运用上一章所说的Cross-Validation的方式来判断模型和起hyperparameters的训练效果，是否需要调整</li></ul><pre><code class="py">from sklearn.model_selection import cross_val_scorescores = cross_val_score(forest_reg, preprocessed_data, labels, scoring= &quot;neg_mean_squared_error&quot;, cv)#分了10组做cross-validationforest_rmse_scores = np.sqrt(-scores)#这是一个utility function，这里区别于cost function。因为前面用的是n_MSE所以这里再取负后，就变成这个值越大，这个模型效果越好了&gt;&gt;&gt; forest_rmse_scores.mean() #这里用平均值来表示10组validation的结果</code></pre><ul><li><strong>Fine-Tune Model:</strong> <ul><li>Grid Search: Use GridSearchCV to search the best combination for hyperparameters values(for all possible situation);</li><li>Randomized Search: use RandomizedSearchCV for large search space;<br><em>我们通过上一步，一个一个来尝试不同的的hyperparameter的话就可以慢慢调到最好结果。这里，sklearn给了我们相应的功能，直接调用就可以，参数间会以排列组合的方式遍历或随机组合（非全部）计算，最后返还最好的参数搭配.</em></li></ul></li></ul><pre><code class="py">from sklearn.model_selection import GridSearchCVparam_grid = [    {&#39;n_estimators&#39;:[3,10,30], &#39;max_features&#39;:[2,4,6,8]},    {&#39;bootstrap&#39;:[False], &#39;n_estimators&#39;:[3,10], &#39;max_features&#39;:[2,3,4]},]#输入想试的组合forest_reg = RandomForestRegressor()grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring=&#39;neg_mean_squared_error&#39;)grid_search = fit(preprocessed_data, labels)&gt;&gt;&gt; grid_search.best_params_#随机的组合，则可以调用RandomizedSearchCV, 方式差不多。</code></pre><ul><li><strong>这里选用的是回归类模型，解决的是回归类问题，所以会选用MSE等上述方式做参考来做validation调整超参，对于分类问题，会可以选用accrucay，recall等评价模型表现（下面会具体整理）。<br>除此之外，对于分类问题，模型选择时还会面临输出值为多维或多种分类，即Multi-problem问题</strong></li></ul><ul><li><p><strong>Multi-Problem</strong></p><ul><li><p>Multiclass Classification</p><ul><li>Two ways to change binary classifiers to multiclass classifier system:<ol><li>One-versus-all (OvA): Train 10 binary classifiers, one for each digit. Select class from the class whose classifier output the highest scores;</li><li>One-versus-one (OvO): Train a binary classifier for every pair of digits. Select class who wins the most duels.</li></ol></li><li>How to choose:<ol><li>Algorithms scale poorly with the size of the training set(i.e., SVM) is preferred to OvO. (Training the small size data set is much faster than the large one);</li><li>For most binary classifiers, OvA is preferred.</li></ol></li></ul></li><li><p>Multilabel Classification<br>  Output contains multiple classes for each instance. </p></li><li><p>Multioutput Classification<br>  It is simply a generalization of multilabel classification where each label can be multiclass(i.e., it can have more than True or False, Haze removing, etc.).<br><strong>大部分的model都是自带适应功能，不需要特意的去调整model到多分类问题。至于OvA还是OvO的问题，我的理解为，model“小组多练”比“大组少练”快，则用OvO，反之则为OvA（大部分为这种）</strong></p></li></ul></li></ul><h3 id="3-Step-of-evaluation"><a href="#3-Step-of-evaluation" class="headerlink" title="3. Step of evaluation"></a>3. Step of evaluation</h3><ul><li><strong>对于回归问题可以用MSE，RMSE等来反馈test set的结果，对于分类问题则还可以通过Confusion Matrix</strong></li><li><p><strong>Confusion Matrix</strong><br>  Reason: Only use accuracy is generally not the preferred performance measure for classifiers, for skewed datasets (i.e., when some classes are much more frequent than others.)</p><div align="center"><br><img src="/img/chapter2/CM.png" width="800" hegiht="200" align="center"><br></div><p>  – 初上述原因之外，Confusion Matrix相比accuracy，也更方便用户具体问题具体分析。举个例子，比如要做一个初步的垃圾邮件过滤，但是要保证所有的非垃圾邮件必须通过这个初步过滤器，所以在这时候也就需要看Trure Positive和Condition Positive的值（也就是Recall），也就暂时可以放宽False positive的要求。而Recall和Precision也是比较常用到的两项。</p></li><li><p><strong>Precision/ Recall Tradeoff</strong></p><ul><li>Set threshold could correct value of the precision and recall (Use the decision_function()  rather ran predict() method, and use confusion_matrix() to see the result):<br><div align="center"><br><img src="/img/chapter2/rp.png" width="400" hegiht="200" align="center"><br></div><ul><li><font color="#FF3333"><strong>Higher</strong></font> threshold —&gt; <font color="#33CC99"><strong>lower</strong></font> recall  and <font color="#FF3333"><strong>Higher</strong></font> precision;</li><li><font color="#33CC99"><strong>Lower</strong></font> threshold —&gt; <font color="#FF3333"><strong>Higher</strong></font> recall and <font color="#33CC99"><strong>lower</strong></font> precision;<br>– 这里可以通过调整Precision/ Recall的方式来满足具体需求，对比不同模型的效果则可以使用对应模型的ROC图。</li></ul></li></ul></li><li><p><strong>The ROC Curve</strong></p><ul><li>The ROC plots the true positive rate(recall) against the false positive rate(FPR, is equal to 1 minus the true negative rate(TNR, specificity)). Thus the ROC curve plots sensitivity(recall) versus 1-specificity.<br><div align="center"><br><img src="/img/chapter2/roc.png" width="400" hegiht="200" align="center"><br></div><ul><li>A good classifier stays as far away from the random line(slight solid, B point)</li><li>Choose PR whenever  positive is rare, if care more about the false positive rate use the<br> ROC curve.</li></ul></li></ul><ul><li>ROC的有多种理解方式，我这里说一下我的理解方式，随着验证过程，Recall不断增大的同时，false positive对应真实值的比例变化越小（FNR），则模型越为理想。即recall上升速度大于FNR的上升速度越多（可以错略的理解成，做对事情的同时犯错越少），模型的工作效果越好，这也是为什么说ROC可以更多的感受False positive rate的原因。这里大于的程度可以看B（最远点）到随机模型线的距离或面积来比较模型优劣。</li></ul></li><li><p><strong>Conclusion</strong></p><ol><li>Use the cross-validation;</li><li>Select the precision/recall tradeoff that fits your needs;</li><li>Compare various models using ROC or ROC AUC(area under the curve) scores</li></ol></li><li><p><strong>Error Analysis</strong></p><ul><li>Look at the confusion matrix:<br><div align="center"><br><img src="/img/chapter2/cmatrix.png" width="400" hegiht="200" align="center"><br></div><ol><li>Call the confusion_matrix, and use the matshow() function;</li><li>Plot the errors, divide each value in the confusion matrix by the number of mages in the corresponding class, and fill the diagonal with zeros.–&gt; P99.<br><strong>Confusion matrix能带来的一个好处就是可以清楚发现模型在那种类别坐判断时会出现较多的问题，方便对症下药。</strong></li></ol></li><li>Fix the specific errors: <ul><li>Gather more training data for these digits;</li><li>Engineer new features;</li><li>Preprocess the image(more stand out, shifting or rotation, etc.).</li></ul></li></ul></li></ul>]]></content>
      
      <categories>
          
          <category> Machine_Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据预处理 </tag>
            
            <tag> Machine Learning </tag>
            
            <tag> 分类和回归基础 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>第一章 Machine Learning基础</title>
      <link href="/2018/06/04/ml_chapter1/"/>
      <url>/2018/06/04/ml_chapter1/</url>
      <content type="html"><![CDATA[<p>哎，打脸了，第一篇就拖了一个星期，结果数据挖掘好像考的也不咋地，哭一会儿。<br><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1529322415583&di=c3f54b957d9f3161cc3adef03d59ba70&imgtype=0&src=http%3A%2F%2Fgfs12.gomein.net.cn%2FL1y9VgB7AT1RCvBVdK.gif" width="200" hegiht="100" align="center"><br>进入正题。</p><p>AI是近些年最火热的话题之一，而Machine Learning则在整个AI领域中占据着举足轻重的地位（尤其Deep Learning得到了飞跃发展的今天）。抛开大家在游戏（比如最近大红的底特律）又或影视中看到的非常概念性的AI产品（西部世界等），就近来看，Machine Learning在现在的科技产品中也扮演着越来越重要的角色，比如人脸识别，比如推荐系统等等。就我个人的想法，当这些特别的个体部分得到充分性的整合后，得到的必然将是颠覆性的产品概念（例如，已经步步走向成熟的智能驾驶系统）。<br>这一章，主要内容包括Machine Learning的定义，分类等大的概念，以及一些我对机器学习这方面自己的理解。（接下来统称ML）</p><h2 id="1-Definition-amp-Why"><a href="#1-Definition-amp-Why" class="headerlink" title="1. Definition &amp;Why"></a>1. Definition &amp;Why</h2><p>书中引用的是Tom Mitchell（1997）对ML的定义：</p><p><em>A computer program is said ot learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.</em></p><div align="center"><br><img src="/img/chapter1/ML_struc.png" width="400" hegiht="200" align="center"><br></div><p>一个简单的例子是，我们要做一个垃圾邮件的分类（T）模型，通过这个模型进行分类得到类别（是否为spam）P，我们通过一些已知分类的邮件输入到这个模型里，根据这些邮件调整这个模型的参数，使其的分类结果P的准确性在实际过程中得到提高。</p><p>当然，这里的数据的形式也是多种多样的，比如在Reinforcement Learning中则是通过定义rewards的方式，使机器在特定policy中，对自身行为进行评判并不断提升（这里的数据则为这个模型在这次表现的action以及其这套actions的结果）。<br>闲话聊多了， 那为什么要运用ML的方式设计模型呢？</p><p>书中的观点整理下来如下，</p><ul><li>Problems for which existing solutions require a lot of hand-tuning or long lists of  rules: one Machine Learning algorithm can often simplify code and perform better.（省事儿，不用设计人员自己进行参数调整）</li><li>Complex problems for which there is  no good solution at all using a traditional approach: the best Machine Learning techniques can find a solution.（光靠主观想，很难设计一个很好又周全的rule）</li><li>Fluctuating environments: a Machine Learning system can adapt to new data.Getting insights about complex problems and large amounts of data. （ML的适应性更强，并且能够get insight）</li></ul><p>总的这样看，ML的作用很明显了。接下来，我们先聊聊，ML这个大家族是怎么进行分类定义的。毕竟解决的问题是多种多样，数据方式也是多种多样的。那么，对应的模型、系统，自然也是。</p><h2 id="2-Types-of-Machine-Learning-Systems"><a href="#2-Types-of-Machine-Learning-Systems" class="headerlink" title="2. Types of Machine Learning Systems"></a>2. Types of Machine Learning Systems</h2><p>在书中，有3种分类的方法（当然，别的分类方式也是有的）：</p><ul><li><p>根据<strong>是否需要人类的supervision</strong>方式分类：<br>  – Supervised Learning<br>  – Unsupervised Learning<br>  – Semisupervised Learning<br>  – Reinforcement Learning</p></li><li><p><strong>训练数据的训练方式</strong>：<br>  – Online learning<br>  – Batch learning</p></li><li><p>根据<strong>模型原理</strong>，即其为简单的进行与已知数据比较还是通过对数据中的patterns学习到一个预测模型：<br>  – Instance-based learning<br>  – Model-based learning</p></li></ul><h3 id="2-1-根据人类的supervision"><a href="#2-1-根据人类的supervision" class="headerlink" title="2.1. 根据人类的supervision"></a>2.1. 根据人类的supervision</h3><h4 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h4><ul><li>In Supervised learning, the training data feed to algorithm includes the Label.</li><li>Task to solve：classification，numeric value(could also used to do the classification–”probability”).</li><li>Most important algorithms（<em>NIB</em>：表示后面的系列将不会总结这个算法）：<br>– K-nearest Neighbors<br>– Linear regression<br>– Logistic Regression<br>– Support Vector Machine(SVMs)<br>– Decision Trees and Random Forests<br>– Neural networks<div align="center"><br><img src="/img/chapter1/ins_spam.png" width="400" hegiht="200" align="center"><br></div></li></ul><p>图片里是一个简单的垃圾短信分类系统，这里的Label也就是-&gt;是ham还是spam，其他的例子比如图片分类，人脸识别等等。我个人的理解，这部分就很像你教小孩子，一样事物是什么的，然他的见识的多，自己摸索到套路了（模型的参数），也就会了，成功率也就高了。</p><h4 id="Unsupervised-learning"><a href="#Unsupervised-learning" class="headerlink" title="Unsupervised learning"></a>Unsupervised learning</h4><ul><li>In Unsupervised learning, the training data is Unlabeled.</li><li>Task to solve：Clustering，Visualizaiton and Dimensionality reduction, Association rule learning(NIB).</li><li>Most important algorithms：<ul><li><strong>Clustering</strong>:<br>  – K-Means(NIB)<br>  – Hierarchical cluster Analysis(HCA)(NIB)<br>  – Expectation Maximization(NIB)</li><li><strong>Visualizaiton and Dimensionality reduction</strong>:<br>  – Principal Component Analysis(PCA)<br>  – Kernel PCA<br>  – Locally-linear Embedding(LIE)(NIB)<br>  – T-distributed Stochastic Neighbor Embedding(t-SNE)(NIB)</li><li><strong>Association rule</strong>:<br>  – Apriori(NIB)<br>  – Eclat(NIB)<div align="center"><br><img src="/img/chapter1/unsupervised.png" width="400" hegiht="200" align="center"><br></div></li></ul></li></ul><p>这是一个clustering的例子，看到图第一眼想可能到的就是KNN等这种聚类算法。unsupervised learning广泛的被应用到，类似于用户分类，topic detection等等这类大数据提取topic又或clustering的方向（采取人为label的话显然是too expensive啦）。当然，既然它可以clustering，它当然就可以用于检测离群值（比如 anomaly detection）。减维的话有比较常见PCA和他的亲戚们，比较直接就是可以减到2～3维来提供viualization，缩减运算量当然也是重要的一点，当然也有很多功能和clustering是比较重合的。<br>Association rule则是寻找大数据中attributes间的联系（读的论文不多，我还没遇到过这个方向的实例）。大概的意思就是，比如，可以通过人们在超市里都买什么，找到买的东西的相应联系，然后下次就可以放一起方便用户购买了。<br>书中对于Unspervised的部分只重点提了PCA相关的算法（减维），个人的理解就是，整本书都是偏向介绍classification 和regression的所以，偏向数据挖掘的算法比如LDA，高斯混合模型等都没有提及。（差点忘了EM，吴老师都说过了，“上帝的算法”）所以这部分的坑就准备在DL前开一章的坑来讲。（日常画饼，哎）</p><h4 id="Semisupervised-learning"><a href="#Semisupervised-learning" class="headerlink" title="Semisupervised learning"></a>Semisupervised learning</h4><ul><li>In Semisupervised learning, the training data are partially labeled.</li><li>Task to solve：Google photos(upload all famliy photos, label several of them, and learner labels all of them)</li><li>Combinations of unsupervised learning and supervised algorithms.</li></ul><p>大部分Semisupervised learning都融合了前面的两种学习系统，书中举了一个比较明显的例子google photos，其实我个人的观点，这个例子不是很好，因为严格意义上来讲，Semisupervised learning是不包含人为干预的，这里则更倾向于active learning。</p><p><em>来点画外音</em> 按照wiki上来讲，active learning其实是Semi learning的一个小弟。在wiki上把他分到了semisupervised learning里了。我自己的观点稍有不同，主动学习的主要思想是：</p><ul><li>实际上，大部分的数据都是为未标记的，那么，从未标记数据中，给用户（又或expert）提一个query example来标记，使得用这个example训练后的收益最大化（甚至可以得到媲美和训练很多其他标记数据的结果）。（个人解释，非官方）</li></ul><p>从整体定义上来看，这个学习方式严格意义上来看，个人觉的不可以完全划分到Semisupervised learning的小弟行列，因为他是需要interaction的。<br>当然以上都是个人的观点，我自己感觉，定义这个东西吧，大概理解就ok。有这空，还是把钻牛角尖的时间，去推推公式更好点。</p><h4 id="Reinforcement-learning"><a href="#Reinforcement-learning" class="headerlink" title="Reinforcement learning"></a>Reinforcement learning</h4><p>In Reinforcement learning,  the system called an agent, can observe the environment, select and perform actions, and get rewards in return(or penalties in the form of negative rewards).</p><div align="center"><br><img src="/img/chapter1/reiforcement.png" width="400" hegiht="200" align="center"><br></div><p>这种方式很有趣，像我前面提到的，他通过制定相关的policy来给模型reward然后去学习，我个人的感觉，这是一个非常有潜力的学习类型，毕竟这才是自学习的精髓，重点是怎么来规定这个policy和reward，现在大部分的运用包括一些模型走路的学习训练（游戏里比较常见），又或者著名的AlphaGo。不出意外，可能这部分的详细整理会出现在Deep learning章的最后一部分，就当是压个轴吧（当然，不出意外的话，哭了）。</p><h3 id="2-2-根据输入数据是fed-by-batch还是online"><a href="#2-2-根据输入数据是fed-by-batch还是online" class="headerlink" title="2.2. 根据输入数据是fed by batch还是online"></a>2.2. 根据输入数据是fed by batch还是online</h3><h4 id="Batch-learning-offline-learning"><a href="#Batch-learning-offline-learning" class="headerlink" title="Batch learning(offline learning)"></a>Batch learning(offline learning)</h4><ul><li>In Batch learning, it must be trained using all the available data.</li></ul><p>这个例子很好说，比如ImageNet比赛中的各种CNN网络～一股脑的训练好去搞定接下来的问题吧。<br>这个方式的弊端也很容易理解，需要足够的数据，再者，再训练的成本比较高（updating）。</p><h4 id="Online-learning"><a href="#Online-learning" class="headerlink" title="Online learning"></a>Online learning</h4><ul><li>In Online learning, you train the system incrementally by feeding it data instances sequentially or small groups(mini-batch). The system can learn about new data on the fly.</li><li><em>Attentions</em> :<ul><li>Learning rate: how fast they should adapt to changing data.<br>  – High: learn fast quickly forget the old data, easily influenced by noise.<br>  – Low: learn slow, have more inertia(惯性), less sensitive to noise.</li><li>If bad data is fed to the system: the system’s performance will gradually decline.<br>  – To avoid: monitor your system closely and promptly switch learning off if detect a drop in performance.<div align="center"><br><img src="/img/chapter1/oline.png" width="400" hegiht="200" align="center"><br></div></li></ul></li></ul><p>这张图是一个简单的Online learning的结构，对比上面的batch learning就可以了，可以incrementally的学习。可以随用随学，很理想。但是缺点也很明显，如上<em>Attentions</em>。</p><h3 id="2-3-根据模型的工作方式-instance-model-based"><a href="#2-3-根据模型的工作方式-instance-model-based" class="headerlink" title="2.3. 根据模型的工作方式 instance/model based"></a>2.3. 根据模型的工作方式 instance/model based</h3><h4 id="Instance-based-learning"><a href="#Instance-based-learning" class="headerlink" title="Instance-based learning"></a>Instance-based learning</h4><ul><li>In  instance-based learning: the system learns the examples by heart, then generalizes to new cases using a similarity measure.<div align="center"><br><img src="/img/chapter1/Instance.png" width="400" hegiht="200" align="center"><br></div></li></ul><p>这部分，我的理解比较粗暴一点。分类的例子，把training data放到数据库，新的数据需要预测，直接和数据库中的例子做比较（这里的比较可以是欧式距离，马式距离等等），找到最优匹配，所以这个方法又称为“胜者为王”法。比较经典的算法，比如KNN。</p><h4 id="Model-based-learning"><a href="#Model-based-learning" class="headerlink" title="Model-based learning"></a>Model-based learning</h4><ul><li>In  Model-based learning: the generalize from a set of examples is to build a model of these examples, the use that model to make predictions.</li><li>Summary:<ul><li>Studied the data</li><li>Selected a model</li><li>Trained it on the training data(minimizing a cost function)</li><li>Apply the model for prediction<div align="center"><br><img src="/img/chapter1/Model.png" width="400" hegiht="200" align="center"><br></div></li></ul></li></ul><h2 id="3-ML中会遇得到种种问题"><a href="#3-ML中会遇得到种种问题" class="headerlink" title="3. ML中会遇得到种种问题"></a>3. ML中会遇得到种种问题</h2><h3 id="3-1-Insufficient-Quantity-of-Training-Data"><a href="#3-1-Insufficient-Quantity-of-Training-Data" class="headerlink" title="3.1. Insufficient Quantity of Training Data"></a>3.1. Insufficient Quantity of Training Data</h3><p>Machine Learning needs enough data for training, even though a simple problems the system needs typically thousands of examples.</p><h3 id="3-2-Non-representative-Training-Data"><a href="#3-2-Non-representative-Training-Data" class="headerlink" title="3.2. Non-representative Training Data"></a>3.2. Non-representative Training Data</h3><p>If the sample is too small, there will be more sampling noise.</p><h3 id="3-3-Poor-Quality-Training-Data"><a href="#3-3-Poor-Quality-Training-Data" class="headerlink" title="3.3. Poor-Quality Training Data"></a>3.3. Poor-Quality Training Data</h3><p>Samples are full of errors, outliers, and noise.</p><h3 id="3-4-Irrelevant-Features"><a href="#3-4-Irrelevant-Features" class="headerlink" title="3.4. Irrelevant Features"></a>3.4. Irrelevant Features</h3><p><em>Solution</em> :</p><ul><li>Features selection: selecting the most useful features to train on among existing features.</li><li>Feature extraction: combining existing features to produce a more useful one.</li><li>Creating new features by gathering new data.</li></ul><p>个人觉得，其中Feature extraction的思想很重要，无论是模型前的数据预处理，还是模型里的kernel去解决非线性问题（比如SVM）。</p><h3 id="3-5-Overfitting-training-data"><a href="#3-5-Overfitting-training-data" class="headerlink" title="3.5. Overfitting training data"></a>3.5. Overfitting training data</h3><p><em>Solution</em> :</p><ul><li>To simplify the model by selecting one with fewer parameters, by reducing the number of attributes in the training data or by constraining the model.</li><li>To gather more training data</li><li>To reduce the noise in the training data</li></ul><p>Overfitting这个问题很经典，也成为了之前Deep learning得到飞速发展前的一道深坎。简单的说就是，参数量太大了，导致训练中每个数据的特点都被模型用各个参数重点关注了（谁让咱手下多呢）。比如这张图，</p><div align="center"><br><img src="https://upload-images.jianshu.io/upload_images/1207849-56df4ac9042948fd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" width="400" hegiht="200" align="center"><br></div><p>可以看出第二个模型就比较满足我们的需要（较为符合实际），虽然有1个点不是很理想。但是第三个图，显然就是用力过猛了（不太符合实际规律一般）。这里的给的解决方法比较笼统，具体在模型里可以有Regularization（例如l1，l2等），又或增加更大的随机性等等（后面根据具体算法具体来讲）。</p><h3 id="3-6-Underfitting-the-training-Data"><a href="#3-6-Underfitting-the-training-Data" class="headerlink" title="3.6. Underfitting the training Data"></a>3.6. Underfitting the training Data</h3><p><em>Solution</em> :</p><ul><li>Selecting a more powerful model.</li><li>Feeding better features to the learning algorithm.</li><li>Reducing the constraints on the model.</li></ul><p>这种方法说白了就是这个模型水平不行，搞不定这个case，去叫个大哥（more powerful models）或者给更多对应的工具（features）。<br>当然，根据上个问题也可能就是overfitting的问题修过度了。</p><h2 id="4-Testing-amp-Validating"><a href="#4-Testing-amp-Validating" class="headerlink" title="4. Testing &amp;Validating"></a>4. Testing &amp;Validating</h2><p>（T：测试这个模型实际中不中，V：调整一下模型里的固有Hyperparameters）</p><ul><li>3 parts:<ul><li>Training set: A set of examples for learning fit the parameters.</li><li>Validation set: A set of examples for tuning the hyperparameters.</li><li>Testing set: A set of examples only to access the performance</li></ul></li><li>Error rate: generalization error or out-of-sample error.</li><li>Training/testing set: usually 8:2<br><em>cross-validation</em> : training set is split into complementary subsets, and each model is trained against a different combination of these subsets and validated against the remaining parts.<div align="center"><br><img src="/img/chapter1/crossvalidation.png" width="400" hegiht="200" align="center"><br></div></li></ul><p>一般的model都经历这个training-validation-testing的过程（一般testing的数据是一开始就直接拿走的，为了保证没有bias，下一章会重点整理），训练好模型了， 但模型大部分都会有一些Hyperparameters，需要咱自己手动调整。这时就又需要一些数据来帮忙调整它们，也就是validation这一部分。最后用testing部分的数据来对这个模型做评价。<br>问题来了，利用一部分训练数据来单独做validation的话，显然就浪费了这部分的有用信息。这时就有了cross-validation这个概念。<br>如图，就是把training的部分分了几块，分别作为validation数据，然后平均一哈作为validation的结果。最后调整好Hyperparameters再总的来training。这个方法经常被用在例如gridsearchCV这种寻找好的Hyperparameters的方法里。</p><h2 id="5-唠叨一下"><a href="#5-唠叨一下" class="headerlink" title="5. 唠叨一下"></a>5. 唠叨一下</h2><p>到这里，这一章就结束了，这里分享一些我自己的一些小想法：<br>一个ML系统能否成功基本可以分为3个大部分，</p><ul><li>第一部分是数据，这个部分决定了模型最后能否真的投入应用，功能就算不强的模型，数据充足的话，它的实施性也是可以得到一定的保障的。（实施性）</li><li>第二部分是模型本身，这个部分相对的决定了这个系统的上限，足够的数据，更好的模型，就意味着更高的准确性（上限性）</li><li>最后的一部分则是硬件，Deep learning能够得到飞速发展的另一个原因也就是硬件上计算能力的进步，加上分布式计算的充分发展，都是系统得到实现的基础。（保证性）</li></ul><p>好啦，大概念的内容就这里截止了，下一章就是运用一个完整的分类项目来介绍一些机器学习中的基本技巧和概念。</p><p>画饼复习路艰难，越学越慢，那就慢慢走吧。<br><img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1529322594639&di=e1f9a8795737706f0cffb9503d28fe71&imgtype=0&src=http%3A%2F%2Fe.hiphotos.baidu.com%2Fimage%2Fpic%2Fitem%2Ffaf2b2119313b07e86f96a4807d7912397dd8c2d.jpg" width="200" hegiht="100" align="center"></p>]]></content>
      
      <categories>
          
          <category> Machine_Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> 基础概念 </tag>
            
            <tag> ML分类 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>关于blog的blablabla</title>
      <link href="/2018/05/24/myblog/"/>
      <url>/2018/05/24/myblog/</url>
      <content type="html"><![CDATA[<p>Hi， 这里是一个来自在CS道路上正在挣扎的码农狗的blog，在拖延症的影响下， （终于*3）用Github Pages把blog搭了。</p><p><strong>鉴于博主是个话唠，欢迎放松心态品尝。</strong></p><h2 id="关于blog"><a href="#关于blog" class="headerlink" title="关于blog"></a>关于blog</h2><h3 id="BLOG的目的"><a href="#BLOG的目的" class="headerlink" title="BLOG的目的"></a>BLOG的目的</h3><p>建这个blog最初目的，也是为了逼迫自己  <strong>周更</strong>  ，9月前复习和整理完之前的笔记。———&gt;&gt;主要还是为了治拖延症<br>如果你对Machine Learning，特别是Deep Learning感兴趣的，欢迎随时来跟我讨论。</p><h3 id="关于Machine-Learning"><a href="#关于Machine-Learning" class="headerlink" title="关于Machine Learning"></a>关于Machine Learning</h3><p>整个的更新的框架，我会直接按照这本书的顺序，一章一章的整理和总结。</p><p>   <strong>V V V</strong></p><p><img src="https://images-eu.ssl-images-amazon.com/images/I/51vPMQ3gJWL.jpg" alt="avatar"></p><p>当然，如果你是ML的初学，我也是非常推荐 <strong>Hands-On Machine Learning with Scikit-Learn &amp; TensorFlow</strong>这本书的，把茫茫的知识点，缕顺的“丝般顺滑”。</p><p>大致的分了两个部分：1.机器学习基础 2.深度学习</p><ul><li>由于笔记中懒惰的我选择了直接搬英文，当然也是怕自己的渣英文强行翻译的话，产生误解，所以主要的躯干我还是会选用英文继续写的.</li><li>除了书中的主要内容的总结，我还会写一点自己的理解和补充内容（如书中未提的EM算法啊，等等），同时也会结合一些自己之前读过的论文和项目做一些小讨论.</li><li>代码部分是基于python3，库的话主要就是sk-learn和tensorflow. </li></ul><p>接下来的第一篇文章呢，就是类似于机器学习的简介， 介绍一些机器学习的分类和基本概念。<br><strong>就算下周两门考试，我也要下周一前更，更更更！欢迎监督！！</strong></p><p>……..给自己画了个大饼，但愿别打脸吧,哎……</p><p><img src="http://ww1.rs.fanjian.net/c/9f/dd/4d/039f480b12dd61d8794d2d801c806c36.gif" alt="avatar"></p><p>最后，博主入ML的大坑没多久，所以欢迎大家纠正错误的部分，这也是我想写blog的最重要的部分，慎重的写自己的每一个总结，认真的听每一条指正。</p><h3 id="关于搭建blog"><a href="#关于搭建blog" class="headerlink" title="关于搭建blog"></a>关于搭建blog</h3><p>自己比较懒，也懒得折腾，就选用了比较方便的hexo搭建这个blog，主题则选用了material，如果有朋友在搭建blog上遇到了问题，或者配置文件上遇到问题也可以和我来进行讨论（当然如果我会的话“滑稽”）。<br>*手机端的评论暂不支持微信登陆（…)</p>]]></content>
      
      <categories>
          
          <category> Machine_Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> hexo </tag>
            
            <tag> 闲聊 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
